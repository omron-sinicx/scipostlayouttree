{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195475e5-aac1-43dc-891c-9b78d1451a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, Counter\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "from detectron2.utils import comm\n",
    "from detectron2.evaluation import DatasetEvaluator\n",
    "from detectron2.structures import pairwise_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from apted import APTED, Config\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1bf90-e867-43bc-8967-a030a61f0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self._records.append(\n",
    "#     dict(\n",
    "#         file_name = os.path.basename(inp[\"file_name\"]),\n",
    "#         image_id  = inp[\"image_id\"],\n",
    "#         ted       = ted,\n",
    "#         steds     = steds,\n",
    "#         reds      = reds\n",
    "#         sim       = sim,\n",
    "#         gt        = gt,\n",
    "#         pred      = pred,\n",
    "#         gt_tree   = gt_tree,\n",
    "#         pred_tree = pred_tree,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca57704-32f2-4a99-811e-4d73509da426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, id, label, bbox, category):\n",
    "        self.id = id\n",
    "        self.label = label\n",
    "        self.bbox = bbox\n",
    "        self.category = category\n",
    "        # List[TreeNode]\n",
    "        self.children = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e31ee-be72-4d55-850b-e76b599f0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00d0e9-b3a6-4c2c-962a-bbea716d5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの順序指定\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "methods = [\"DRGG\", \"DRGGBBoxEmbTFEnc\"]\n",
    "# beam_widths = [1, 5, 10, 15, 20, 25, 30]\n",
    "beam_widths = [1, 20]\n",
    "\n",
    "# 出力ディレクトリ\n",
    "base_dir = \"./output_20250710\"\n",
    "\n",
    "# 結果保存用リスト\n",
    "summary_records = []\n",
    "\n",
    "# すべての予測を格納する辞書\n",
    "all_preds_dict = {}\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in methods:\n",
    "        for beam_width in beam_widths:\n",
    "            file_path = os.path.join(base_dir, f\"gtbbox_{backbone}_{method}\", f\"tree_predictions.bw{beam_width}.pt\")\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"[WARN] Not found: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                preds = torch.load(file_path)\n",
    "                all_preds_dict[(backbone, method, beam_width)] = preds  # ← 保存\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Could not load {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            ted_sum = steds_sum = reds_sum = 0.0\n",
    "            count = 0\n",
    "            for pred in preds:\n",
    "                if all(k in pred for k in [\"ted\", \"steds\", \"reds\"]):\n",
    "                    ted_sum += pred[\"ted\"]\n",
    "                    steds_sum += pred[\"steds\"]\n",
    "                    reds_sum += pred[\"reds\"]\n",
    "                    count += 1\n",
    "\n",
    "            if count == 0:\n",
    "                continue\n",
    "\n",
    "            summary_records.append({\n",
    "                \"Backbone\": backbone,\n",
    "                \"Method\": method,\n",
    "                \"Beam Width\": beam_width,\n",
    "                \"STEDS\": steds_sum / count * 100,\n",
    "                \"REDS\": reds_sum / count * 100,\n",
    "                \"TED\": ted_sum / count,\n",
    "            })\n",
    "\n",
    "# データフレーム化＆整形\n",
    "df = pd.DataFrame(summary_records)\n",
    "df = df.sort_values(by=[\"Backbone\", \"Method\", \"Beam Width\"]).reset_index(drop=True)\n",
    "\n",
    "# LaTeX形式で出力\n",
    "latex_table = df.to_latex(index=False, float_format=\"%.2f\", column_format=\"lllrrr\", escape=False)\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a14a8-9f4c-4bf4-acfa-5cd04d0180f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def get_valid_scores(preds, key):\n",
    "    return [p[key] for p in preds if all(k in p for k in [\"ted\", \"steds\", \"reds\"])]\n",
    "\n",
    "def add_wilcoxon_stars_against_base(df, all_preds_dict):\n",
    "    df_new = df.copy()\n",
    "    marked_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        backbone = row[\"Backbone\"]\n",
    "        method = row[\"Method\"]\n",
    "        beam_width = row[\"Beam Width\"]\n",
    "\n",
    "        # 基準設定かどうか\n",
    "        if method == \"DRGG\" and beam_width == 1:\n",
    "            marked_rows.append(row)\n",
    "            continue\n",
    "\n",
    "        key_base = (backbone, \"DRGG\", 1)\n",
    "        key_target = (backbone, method, beam_width)\n",
    "\n",
    "        if key_base not in all_preds_dict or key_target not in all_preds_dict:\n",
    "            marked_rows.append(row)\n",
    "            continue\n",
    "\n",
    "        base_preds = all_preds_dict[key_base]\n",
    "        target_preds = all_preds_dict[key_target]\n",
    "\n",
    "        out_row = row.copy()\n",
    "\n",
    "        for key in [\"TED\", \"STEDS\", \"REDS\"]:\n",
    "            metric = key.lower()\n",
    "            base_vals = get_valid_scores(base_preds, metric)\n",
    "            target_vals = get_valid_scores(target_preds, metric)\n",
    "\n",
    "            if len(base_vals) == 0 or len(target_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            n = min(len(base_vals), len(target_vals))\n",
    "            try:\n",
    "                _, p_val = wilcoxon(base_vals[:n], target_vals[:n])\n",
    "                assert p_val < 0.05\n",
    "                val = row[key]\n",
    "                out_row[key] = f\"{val:.2f}*\" if isinstance(val, float) else f\"{val}*\"\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Wilcoxon failed for {key_base} vs {key_target}: {e}\")\n",
    "                continue\n",
    "\n",
    "        marked_rows.append(out_row)\n",
    "\n",
    "    df_marked = pd.DataFrame(marked_rows)\n",
    "    return df_marked\n",
    "\n",
    "# Wilcoxon結果を DRGG, bw=1 をベースとして反映\n",
    "df_marked = add_wilcoxon_stars_against_base(df, all_preds_dict)\n",
    "\n",
    "def get_decoder_display_name(method: str, beam_width: int) -> str:\n",
    "    if method == \"DRGG\":\n",
    "        return \"DRGG\" if beam_width == 1 else \"DRGG-BS\"\n",
    "    elif method == \"DRGGBBoxEmbTFEnc\":\n",
    "        return \"DRGG-BE\" if beam_width == 1 else \"DRGG-BEBS\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\"\n",
    "}\n",
    "\n",
    "backbone_display_order = [\n",
    "    \"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"\n",
    "]\n",
    "\n",
    "def get_decoder_sort_key(method: str, beam_width: int) -> int:\n",
    "    if method == \"DRGG\" and beam_width == 1:\n",
    "        return 1\n",
    "    elif method == \"DRGGBBoxEmbTFEnc\" and beam_width == 1:\n",
    "        return 2\n",
    "    elif method == \"DRGG\" and beam_width > 1:\n",
    "        return 3\n",
    "    elif method == \"DRGGBBoxEmbTFEnc\" and beam_width > 1:\n",
    "        return 4\n",
    "    else:\n",
    "        return 99  # fallback\n",
    "\n",
    "def format_latex_table(df):\n",
    "    df[\"BackboneDisplay\"] = df[\"Backbone\"].map(backbone_name_map)\n",
    "    df[\"Decoder\"] = df.apply(lambda row: get_decoder_display_name(row[\"Method\"], row[\"Beam Width\"]), axis=1)\n",
    "    df[\"DecoderOrder\"] = df.apply(lambda row: get_decoder_sort_key(row[\"Method\"], row[\"Beam Width\"]), axis=1)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{tabular}{ll|rrr}\")\n",
    "    lines.append(r\"\\toprule\")\n",
    "    lines.append(r\"Backbone & Decoder & STEDS & REDS & TED \\\\\")\n",
    "    lines.append(r\"\\midrule\")\n",
    "\n",
    "    for i, backbone_disp in enumerate(backbone_display_order):\n",
    "        group = df[df[\"BackboneDisplay\"] == backbone_disp].copy()\n",
    "        group = group.sort_values(\"DecoderOrder\").reset_index(drop=True)\n",
    "        for j, row in group.iterrows():\n",
    "            decoder = row[\"Decoder\"]\n",
    "            steds = _format_val(row[\"STEDS\"])\n",
    "            reds = _format_val(row[\"REDS\"])\n",
    "            ted = _format_val(row[\"TED\"])\n",
    "\n",
    "            if j == 0:\n",
    "                lines.append(rf\"\\multirow{{{len(group)}}}{{*}}{{{backbone_disp}}} & {decoder} & {steds} & {reds} & {ted} \\\\\")\n",
    "            else:\n",
    "                lines.append(rf\"    & {decoder} & {steds} & {reds} & {ted} \\\\\")\n",
    "        if i < len(backbone_display_order) - 1:\n",
    "            lines.append(r\"\\midrule\")\n",
    "    lines.append(r\"\\bottomrule\")\n",
    "    lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _format_val(val):\n",
    "    if isinstance(val, str) and val.endswith(\"*\"):\n",
    "        return f\"{val[:-1]}$^{{\\\\ast}}$\"\n",
    "    return f\"{val:.2f}\" if isinstance(val, float) else str(val)\n",
    "\n",
    "# 出力\n",
    "latex_table = format_latex_table(df_marked)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005c7b5-53ae-4d8a-9866-39d3e5ff608e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 条件に合うデータを抽出\n",
    "target_method = \"DRGGBBoxEmbTFEnc\"\n",
    "target_beam_width = 20\n",
    "\n",
    "records = []\n",
    "\n",
    "for (backbone, method, beam_width), preds in all_preds_dict.items():\n",
    "    if method == target_method and beam_width == target_beam_width:\n",
    "        for pred in preds:\n",
    "            if \"steds\" in pred and \"image_id\" in pred:\n",
    "                records.append({\n",
    "                    \"File Name\": pred[\"file_name\"],\n",
    "                    \"STEDS\": pred[\"steds\"]\n",
    "                })\n",
    "\n",
    "# DataFrame に変換\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# image_id ごとに STEDS を平均\n",
    "df_mean = df.groupby(\"File Name\", as_index=False).agg({\"STEDS\": \"mean\"})\n",
    "\n",
    "# 昇順にソート\n",
    "df_sorted = df_mean.sort_values(by=\"STEDS\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 表示\n",
    "df_sorted\n",
    "\n",
    "N = 100  # 任意の上位件数に設定（例：20件）\n",
    "\n",
    "# 上位 N 件を抽出\n",
    "top_n_df = df_sorted.head(N)\n",
    "\n",
    "# 表示\n",
    "print(top_n_df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b36a6c-a623-4670-8ace-04e146230243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 評価指標とキー対応\n",
    "metrics = [\"TED\", \"STEDS\", \"REDS\"]\n",
    "metric_keys = {\"TED\": \"ted\", \"STEDS\": \"steds\", \"REDS\": \"reds\"}\n",
    "\n",
    "# backbone 表示ラベル変換\n",
    "backbone_labels = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "    \"dit_base\": \"DiT\"\n",
    "}\n",
    "\n",
    "# method 表示とハッチパターン\n",
    "method_hatch_map = {\n",
    "    \"DRGG\": None,\n",
    "    \"DRGG-BE\": \"//\",\n",
    "    \"DRGG-BS\": \"\\\\\\\\\",\n",
    "    \"DRGG-BEBS\": \"xx\"\n",
    "}\n",
    "\n",
    "beam_widths = [1, 20]\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"dit_base\", \"internimage_base_4scale\"]\n",
    "methods = [\"DRGG\", \"DRGGBBoxEmbTFEnc\"]\n",
    "\n",
    "# 色設定\n",
    "color_list = plt.cm.tab20.colors\n",
    "\n",
    "for m in metrics:\n",
    "    label_to_values = OrderedDict()  # 順序を保持\n",
    "    label_to_hatch = OrderedDict()\n",
    "\n",
    "    for backbone in backbones:\n",
    "        backbone_display = backbone_labels.get(backbone, backbone)\n",
    "        for beam_width in beam_widths:\n",
    "            for method in methods:        \n",
    "                key = (backbone, method, beam_width)\n",
    "                if key not in all_preds_dict:\n",
    "                    continue\n",
    "\n",
    "                preds = all_preds_dict[key]\n",
    "                values = []\n",
    "                for pred in preds:\n",
    "                    k = metric_keys[m]\n",
    "                    if k in pred and pred[k] is not None:\n",
    "                        value = pred[k] * 100 if m in (\"STEDS\", \"REDS\") else pred[k]\n",
    "                        values.append(value)\n",
    "\n",
    "                if method == \"DRGG\":\n",
    "                    method_display = \"DRGG-BS\" if beam_width == 20 else \"DRGG\"\n",
    "                elif method == \"DRGGBBoxEmbTFEnc\":\n",
    "                    method_display = \"DRGG-BEBS\" if beam_width == 20 else \"DRGG-BE\"\n",
    "                else:\n",
    "                    method_display = method\n",
    "\n",
    "                label = f\"{backbone_display}-{method_display}\"\n",
    "                label_to_values[label] = values\n",
    "                label_to_hatch[label] = method_hatch_map.get(method_display, None)\n",
    "\n",
    "    # 描画設定\n",
    "    bins = np.arange(0, 110, 10)\n",
    "    bin_width = 9\n",
    "    num_labels = len(label_to_values)\n",
    "    bar_width = bin_width / (num_labels + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    for i, (label, values) in enumerate(label_to_values.items()):\n",
    "        counts, _ = np.histogram(values, bins=bins)\n",
    "        bin_positions = bins[:-1] + i * bar_width\n",
    "\n",
    "        plt.bar(\n",
    "            bin_positions,\n",
    "            counts,\n",
    "            width=bar_width,\n",
    "            label=label,\n",
    "            color=color_list[i % len(color_list)],\n",
    "            hatch=label_to_hatch[label],\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "    plt.yscale(\"log\", base=2)\n",
    "    plt.xlabel(f\"{m}\", fontsize=14)\n",
    "    plt.ylabel(\"Log-scale Frequency\", fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    legend_loc = \"upper left\" if m in (\"STEDS\", \"REDS\") else \"upper right\"\n",
    "    plt.legend(fontsize=10, title=\"Backbone-Decoder\", title_fontsize=10, loc=legend_loc)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./figures/{m.lower()}_histogram.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{m.lower()}_histogram.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e5c0c-2f5f-4d44-b4df-343de0e99adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Backbone 表示名変換\n",
    "# backbone_labels = {\n",
    "#     \"r50_4scale\": \"ResNet-50\",\n",
    "#     \"vitdet_base_4scale\": \"ViT\",\n",
    "#     \"swin_base_384_4scale\": \"Swin\",\n",
    "#     \"internimage_base_4scale\": \"InternImage\",\n",
    "#     \"dit_base\": \"DiT\"\n",
    "# }\n",
    "# backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"dit_base\", \"internimage_base_4scale\"]\n",
    "\n",
    "# # Method 表示名変換（BS 表示なし）\n",
    "# method_display_map = {\n",
    "#     \"DRGG\": \"DRGG\",\n",
    "#     \"DRGGBBoxEmbTFEnc\": \"DRGG-BE\"\n",
    "# }\n",
    "\n",
    "# # 対象のビーム幅\n",
    "# target_beam_widths = [1, 5, 10, 15, 20, 25, 30]\n",
    "# df_plot = df[df[\"Beam Width\"].isin(target_beam_widths)].copy()\n",
    "\n",
    "# # 表示用列を追加\n",
    "# df_plot[\"Backbone Display\"] = df_plot[\"Backbone\"].map(backbone_labels)\n",
    "# df_plot[\"Method Display\"] = df_plot[\"Method\"].map(method_display_map)\n",
    "# df_plot[\"Legend Label\"] = df_plot[\"Backbone Display\"] + \"-\" + df_plot[\"Method Display\"]\n",
    "\n",
    "# # 表示順に並べるためのキー\n",
    "# ordered_labels = []\n",
    "# for b in backbones:\n",
    "#     b_disp = backbone_labels[b]\n",
    "#     for m in [\"DRGG\", \"DRGGBBoxEmbTFEnc\"]:\n",
    "#         m_disp = method_display_map[m]\n",
    "#         ordered_labels.append(f\"{b_disp}-{m_disp}\")\n",
    "\n",
    "# # 指標と色\n",
    "# metrics = [\"STEDS\", \"REDS\", \"TED\"]\n",
    "# colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "# for metric, color in zip(metrics, colors):\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     for label in ordered_labels:\n",
    "#         group = df_plot[df_plot[\"Legend Label\"] == label]\n",
    "#         if group.empty:\n",
    "#             continue\n",
    "#         group = group.sort_values(\"Beam Width\")\n",
    "#         plt.plot(group[\"Beam Width\"], group[metric],\n",
    "#                  marker='o', label=label)\n",
    "\n",
    "#     plt.xlabel(\"Beam Width\", fontsize=14)\n",
    "#     plt.ylabel(metric, fontsize=14)\n",
    "#     plt.xticks(fontsize=14)\n",
    "#     plt.yticks(fontsize=14)\n",
    "#     plt.ylim(bottom=0)\n",
    "#     plt.title(f\"{metric} vs Beam Width\", fontsize=14)\n",
    "#     plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "#     # 凡例位置調整\n",
    "#     if metric in (\"STEDS\", \"REDS\"):\n",
    "#         legend_loc = \"lower right\"\n",
    "#         plt.legend(title=\"Backbone-Decoder\", loc=legend_loc)\n",
    "#     elif metric == \"TED\":\n",
    "#         # 左下から少し右上にずらす\n",
    "#         plt.legend(title=\"Backbone-Decoder\", loc=\"lower left\", bbox_to_anchor=(0.2, 0.0))\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"./figures/{metric.lower()}_beamwidth.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.savefig(f\"./figures/{metric.lower()}_beamwidth.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b0453-05db-4f8a-8bed-52d9a3459d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加メソッド\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "methods_to_add = [\"DRGGTextEmbTFEnc\", \"DRGGBBoxEmbTextEmbTFEnc\"]\n",
    "beam_widths = [1, 20]\n",
    "\n",
    "# 保存用\n",
    "new_summary_records = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in methods_to_add:\n",
    "        for beam_width in beam_widths:\n",
    "            key = (backbone, method, beam_width)\n",
    "            if key in all_preds_dict:\n",
    "                preds = all_preds_dict[key]\n",
    "            else:\n",
    "                file_path = os.path.join(base_dir, f\"gtbbox_{backbone}_{method}\", f\"tree_predictions.bw{beam_width}.pt\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"[WARN] Not found: {file_path}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    preds = torch.load(file_path)\n",
    "                    all_preds_dict[key] = preds\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Could not load {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            ted_sum = steds_sum = reds_sum = 0.0\n",
    "            count = 0\n",
    "            for pred in preds:\n",
    "                if all(k in pred for k in [\"ted\", \"steds\", \"reds\"]):\n",
    "                    ted_sum += pred[\"ted\"]\n",
    "                    steds_sum += pred[\"steds\"]\n",
    "                    reds_sum += pred[\"reds\"]\n",
    "                    count += 1\n",
    "            if count == 0:\n",
    "                continue\n",
    "            new_summary_records.append({\n",
    "                \"Backbone\": backbone,\n",
    "                \"Method\": method,\n",
    "                \"Beam Width\": beam_width,\n",
    "                \"STEDS\": steds_sum / count * 100,\n",
    "                \"REDS\": reds_sum / count * 100,\n",
    "                \"TED\": ted_sum / count,\n",
    "            })\n",
    "\n",
    "# --- 新旧まとめて結合・整形 ---\n",
    "df_new = pd.DataFrame(summary_records + new_summary_records)\n",
    "df_new = df_new.sort_values(by=[\"Backbone\", \"Method\", \"Beam Width\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df942da0-52f0-4472-b2ab-d7e0b73818b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LaTeX 出力 ---\n",
    "latex_table = df_new.to_latex(\n",
    "    index=False,\n",
    "    float_format=\"%.2f\",\n",
    "    column_format=\"lllrrr\",\n",
    "    escape=False,\n",
    "    caption=\"STEDS, REDS, and TED scores per Backbone, Method, and Beam Width.\",\n",
    "    label=\"tab:tree_scores_extended\"\n",
    ")\n",
    "print(\"\\n=== LaTeX ===\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aea5a0-191e-4752-9e33-563f0fece30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Wilcoxon: DRGG(bw=1) を基準に有意差を付加 ===\n",
    "def get_valid_scores(preds, key):\n",
    "    return [p[key] for p in preds if all(k in p for k in [\"ted\", \"steds\", \"reds\"])]\n",
    "\n",
    "def add_wilcoxon_stars_against_base(df, all_preds_dict):\n",
    "    marked_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        backbone = row[\"Backbone\"]\n",
    "        method = row[\"Method\"]\n",
    "        beam_width = row[\"Beam Width\"]\n",
    "\n",
    "        key_target = (backbone, method, beam_width)\n",
    "        key_base = (backbone, \"DRGG\", 1)\n",
    "\n",
    "        if method == \"DRGG\" and beam_width == 1:\n",
    "            marked_rows.append(row)\n",
    "            continue\n",
    "\n",
    "        if key_base not in all_preds_dict or key_target not in all_preds_dict:\n",
    "            marked_rows.append(row)\n",
    "            continue\n",
    "\n",
    "        base_preds = all_preds_dict[key_base]\n",
    "        target_preds = all_preds_dict[key_target]\n",
    "\n",
    "        out_row = row.copy()\n",
    "\n",
    "        for metric_name in [\"TED\", \"STEDS\", \"REDS\"]:\n",
    "            metric = metric_name.lower()\n",
    "            base_vals = get_valid_scores(base_preds, metric)\n",
    "            target_vals = get_valid_scores(target_preds, metric)\n",
    "\n",
    "            if len(base_vals) == 0 or len(target_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            n = min(len(base_vals), len(target_vals))\n",
    "            try:\n",
    "                _, p_val = wilcoxon(base_vals[:n], target_vals[:n])\n",
    "                if p_val < 0.05:\n",
    "                    val = row[metric_name]\n",
    "                    out_row[metric_name] = f\"{val:.2f}*\" if isinstance(val, float) else f\"{val}*\"\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Wilcoxon failed for {key_base} vs {key_target}: {e}\")\n",
    "                continue\n",
    "\n",
    "        marked_rows.append(out_row)\n",
    "\n",
    "    return pd.DataFrame(marked_rows)\n",
    "\n",
    "# === 2. 表示設定 ===\n",
    "decoder_display_map = {\n",
    "    (\"DRGG\", 1): \"DRGG\",\n",
    "    (\"DRGGBBoxEmbTFEnc\", 1): \"DRGG-BE\",\n",
    "    (\"DRGG\", 20): \"DRGG-BS\",\n",
    "    (\"DRGGBBoxEmbTFEnc\", 20): \"DRGG-BEBS\",\n",
    "    (\"DRGGTextEmbTFEnc\", 1): \"DRGG-TE\",\n",
    "    (\"DRGGTextEmbTFEnc\", 20): \"DRGG-TEBS\",\n",
    "    (\"DRGGBBoxEmbTextEmbTFEnc\", 1): \"DRGG-BETE\",\n",
    "    (\"DRGGBBoxEmbTextEmbTFEnc\", 20): \"DRGG-BETEBS\"\n",
    "}\n",
    "\n",
    "decoder_order = [\"DRGG\", \"DRGG-BE\", \"DRGG-BS\", \"DRGG-BEBS\", \"DRGG-TE\", \"DRGG-TEBS\", \"DRGG-BETE\", \"DRGG-BETEBS\"]\n",
    "\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\"\n",
    "}\n",
    "\n",
    "backbone_display_order = [\"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"]\n",
    "\n",
    "# === 3. LaTeX テーブル整形 ===\n",
    "def _format_val(val):\n",
    "    if isinstance(val, str) and val.endswith(\"*\"):\n",
    "        return f\"{val[:-1]}$^{{\\\\ast}}$\"\n",
    "    return f\"{val:.2f}\" if isinstance(val, float) else str(val)\n",
    "\n",
    "def format_latex_table(df):\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{tabular}{ll|rrr}\")\n",
    "    lines.append(r\"\\toprule\")\n",
    "    lines.append(r\"Backbone & Decoder & STEDS & REDS & TED \\\\\")\n",
    "    lines.append(r\"\\midrule\")\n",
    "\n",
    "    for i, backbone_disp in enumerate(backbone_display_order):\n",
    "        group = df[df[\"BackboneDisplay\"] == backbone_disp].copy()\n",
    "        group = group.sort_values(\"DecoderOrder\").reset_index(drop=True)\n",
    "        for j, row in group.iterrows():\n",
    "            decoder = row[\"Decoder\"]\n",
    "            steds = _format_val(row[\"STEDS\"])\n",
    "            reds = _format_val(row[\"REDS\"])\n",
    "            ted = _format_val(row[\"TED\"])\n",
    "            if j == 0:\n",
    "                lines.append(rf\"\\multirow{{{len(group)}}}{{*}}{{{backbone_disp}}} & {decoder} & {steds} & {reds} & {ted} \\\\\")\n",
    "            else:\n",
    "                lines.append(rf\"    & {decoder} & {steds} & {reds} & {ted} \\\\\")\n",
    "        if i < len(backbone_display_order) - 1:\n",
    "            lines.append(r\"\\midrule\")\n",
    "    lines.append(r\"\\bottomrule\")\n",
    "    lines.append(r\"\\end{tabular}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# === 4. 実行 ===\n",
    "# df_new を元にフィルタ（対象は DRGG(bw=1) + 各 method bw=20）\n",
    "df_filtered = df_new.copy()\n",
    "df_filtered[\"Decoder\"] = df_filtered.apply(\n",
    "    lambda row: decoder_display_map.get((row[\"Method\"], row[\"Beam Width\"])), axis=1\n",
    ")\n",
    "df_filtered = df_filtered[df_filtered[\"Decoder\"].notnull()].copy()\n",
    "df_filtered[\"DecoderOrder\"] = df_filtered[\"Decoder\"].apply(lambda d: decoder_order.index(d))\n",
    "df_filtered[\"BackboneDisplay\"] = df_filtered[\"Backbone\"].map(backbone_name_map)\n",
    "\n",
    "# 有意差付加\n",
    "df_marked = add_wilcoxon_stars_against_base(df_filtered, all_preds_dict)\n",
    "\n",
    "# LaTeX出力\n",
    "latex_table = format_latex_table(df_marked)\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c6bf8-a26a-4f5c-a592-19f4057cee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 追加メソッド\n",
    "# methods_to_add = [\"DRGGPositionEmbTFEnc\", \"DRGGClassEmbTFEnc\"]\n",
    "# beam_widths = [1, 20]\n",
    "\n",
    "# # 保存用\n",
    "# new_summary_records = []\n",
    "\n",
    "# for backbone in backbones:\n",
    "#     for method in methods_to_add:\n",
    "#         for beam_width in beam_widths:\n",
    "#             key = (backbone, method, beam_width)\n",
    "#             if key in all_preds_dict:\n",
    "#                 preds = all_preds_dict[key]\n",
    "#             else:\n",
    "#                 file_path = os.path.join(base_dir, f\"gtbbox_{backbone}_{method}\", f\"tree_predictions.bw{beam_width}.pt\")\n",
    "#                 if not os.path.exists(file_path):\n",
    "#                     print(f\"[WARN] Not found: {file_path}\")\n",
    "#                     continue\n",
    "#                 try:\n",
    "#                     preds = torch.load(file_path)\n",
    "#                     all_preds_dict[key] = preds\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"[ERROR] Could not load {file_path}: {e}\")\n",
    "#                     continue\n",
    "\n",
    "#             ted_sum = steds_sum = reds_sum = 0.0\n",
    "#             count = 0\n",
    "#             for pred in preds:\n",
    "#                 if all(k in pred for k in [\"ted\", \"steds\", \"reds\"]):\n",
    "#                     ted_sum += pred[\"ted\"]\n",
    "#                     steds_sum += pred[\"steds\"]\n",
    "#                     reds_sum += pred[\"reds\"]\n",
    "#                     count += 1\n",
    "#             if count == 0:\n",
    "#                 continue\n",
    "#             new_summary_records.append({\n",
    "#                 \"Backbone\": backbone,\n",
    "#                 \"Method\": method,\n",
    "#                 \"Beam Width\": beam_width,\n",
    "#                 \"STEDS\": steds_sum / count * 100,\n",
    "#                 \"REDS\": reds_sum / count * 100,\n",
    "#                 \"TED\": ted_sum / count,\n",
    "#             })\n",
    "\n",
    "# # --- 新旧まとめて結合・整形 ---\n",
    "# df_new = pd.DataFrame(summary_records + new_summary_records)\n",
    "# df_new = df_new.sort_values(by=[\"Backbone\", \"Method\", \"Beam Width\"]).reset_index(drop=True)\n",
    "\n",
    "# # --- LaTeX 出力 ---\n",
    "# latex_table = df_new.to_latex(\n",
    "#     index=False,\n",
    "#     float_format=\"%.2f\",\n",
    "#     column_format=\"lllrrr\",\n",
    "#     escape=False,\n",
    "#     caption=\"STEDS, REDS, and TED scores per Backbone, Method, and Beam Width.\",\n",
    "#     label=\"tab:tree_scores_extended\"\n",
    "# )\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b46019-7102-4ddd-877d-24c7d645f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from math import atan2, degrees\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- 方向分類などの関数 ---\n",
    "def dfs_all_nodes(node):\n",
    "    nodes = [node]\n",
    "    for child in node.children:\n",
    "        nodes.extend(dfs_all_nodes(child))\n",
    "    return nodes\n",
    "\n",
    "def bbox_center(bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    return (x_min + x_max) / 2, (y_min + y_max) / 2\n",
    "\n",
    "def classify_8_directions(dx, dy):\n",
    "    angle = (degrees(atan2(dy, dx)) + 360) % 360\n",
    "    if (337.5 <= angle < 360) or (0 <= angle < 22.5):\n",
    "        return \"右\"\n",
    "    elif 22.5 <= angle < 67.5:\n",
    "        return \"右下\"\n",
    "    elif 67.5 <= angle < 112.5:\n",
    "        return \"下\"\n",
    "    elif 112.5 <= angle < 157.5:\n",
    "        return \"左下\"\n",
    "    elif 157.5 <= angle < 202.5:\n",
    "        return \"左\"\n",
    "    elif 202.5 <= angle < 247.5:\n",
    "        return \"左上\"\n",
    "    elif 247.5 <= angle < 292.5:\n",
    "        return \"上\"\n",
    "    elif 292.5 <= angle < 337.5:\n",
    "        return \"右上\"\n",
    "    else:\n",
    "        return \"不明\"\n",
    "\n",
    "# --- 方向カテゴリ（順序固定） ---\n",
    "direction_types = [\"右\", \"右下\", \"下\", \"左下\", \"左\", \"左上\", \"上\", \"右上\"]\n",
    "\n",
    "# --- 外部から与えられた preds データを使う ---\n",
    "# all_preds_dict[(backbone, method, beam_width)] に格納されている前提\n",
    "# 例: all_preds_dict[(\"r50_4scale\", \"DRGG\", 1)]\n",
    "\n",
    "results = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in methods:\n",
    "        key1 = (backbone, method, 1)\n",
    "        key20 = (backbone, method, 20)\n",
    "\n",
    "        if key1 not in all_preds_dict or key20 not in all_preds_dict:\n",
    "            print(f\"[WARN] Missing preds for {backbone}-{method}\")\n",
    "            continue\n",
    "\n",
    "        preds1 = all_preds_dict[key1]\n",
    "        preds20 = all_preds_dict[key20]\n",
    "\n",
    "        # --- REDS差分の準備 ---\n",
    "        file_to_reds_diff = {}\n",
    "        for p1 in preds1:\n",
    "            fname = p1[\"file_name\"]\n",
    "            reds1 = p1[\"reds\"]\n",
    "            p20 = next((p for p in preds20 if p[\"file_name\"] == fname), None)\n",
    "            if p20 is not None and \"reds\" in p20:\n",
    "                reds20 = p20[\"reds\"]\n",
    "                file_to_reds_diff[fname] = reds20 - reds1\n",
    "\n",
    "        # --- 視線方向集計（8方向） ---\n",
    "        file_to_direction_counts = defaultdict(Counter)\n",
    "\n",
    "        for p1 in preds1:\n",
    "            fname = p1[\"file_name\"]\n",
    "            if fname not in file_to_reds_diff:\n",
    "                continue\n",
    "            root = p1[\"pred_tree\"]\n",
    "            ordered_nodes = dfs_all_nodes(root)\n",
    "            nodes = [n for n in ordered_nodes if n.category != -1]\n",
    "\n",
    "            for i in range(len(nodes) - 1):\n",
    "                x1, y1 = bbox_center(nodes[i].bbox)\n",
    "                x2, y2 = bbox_center(nodes[i + 1].bbox)\n",
    "                dx, dy = x2 - x1, y2 - y1\n",
    "\n",
    "                if dx == 0 and dy == 0:\n",
    "                    continue\n",
    "\n",
    "                direction = classify_8_directions(dx, dy)\n",
    "                if direction != \"不明\":\n",
    "                    file_to_direction_counts[fname][direction] += 1\n",
    "\n",
    "        # --- DataFrame 構築 ---\n",
    "        df_direction = pd.DataFrame.from_dict(file_to_direction_counts, orient=\"index\").fillna(0)\n",
    "        df_reds = pd.DataFrame.from_dict(file_to_reds_diff, orient=\"index\", columns=[\"REDS_diff\"])\n",
    "        df_combined = df_direction.join(df_reds).dropna()\n",
    "\n",
    "        # --- 相関計算 ---\n",
    "        for direction in direction_types:\n",
    "            reds = df_combined[\"REDS_diff\"].values\n",
    "            counts = df_combined[direction].values\n",
    "            r, p = pearsonr(counts, reds)\n",
    "            results.append({\n",
    "                \"Backbone\": backbone,\n",
    "                \"Method\": method,\n",
    "                \"Direction\": direction,\n",
    "                \"Pearson r\": r,\n",
    "                \"p-value\": p\n",
    "            })\n",
    "\n",
    "# --- 出力 ---\n",
    "df_corr_all = pd.DataFrame(results)\n",
    "\n",
    "# print(\"=== Correlation Results ===\")\n",
    "# print(df_corr_all.to_string(index=False))\n",
    "\n",
    "# latex = df_corr_all.to_latex(\n",
    "#     index=False,\n",
    "#     float_format=\"%.4f\",\n",
    "#     caption=\"Correlation between REDS difference (Beam 1→20) and directional transitions per image, by backbone and method.\",\n",
    "#     label=\"tab:reds_direction_corr_all\"\n",
    "# )\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3d46a-d381-4872-b03a-296412b3a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- r†形式で整形 ---\n",
    "def format_r_dagger(row):\n",
    "    r_val = f\"{row['Pearson r']:.3f}\"\n",
    "    if row[\"p-value\"] < 0.001:\n",
    "        return f\"{r_val}$\\\\dagger$\"\n",
    "    else:\n",
    "        return r_val\n",
    "\n",
    "df_corr_all[\"r(p)\"] = df_corr_all.apply(format_r_dagger, axis=1)\n",
    "\n",
    "# --- ピボット（方向ごとの列に） ---\n",
    "df_pivot = df_corr_all.pivot(index=[\"Backbone\", \"Method\"], columns=\"Direction\", values=\"r(p)\").reset_index()\n",
    "\n",
    "# --- 明示的なカラム順指定 ---\n",
    "ordered_cols = [\"Backbone\", \"Method\", \"右\", \"右下\", \"下\", \"左下\", \"左\", \"左上\", \"上\", \"右上\"]\n",
    "df_pivot = df_pivot[ordered_cols]\n",
    "\n",
    "# --- LaTeX書き出し ---\n",
    "latex_table = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"ll\" + \"c\" * 8,\n",
    "    caption=r\"Correlation between REDS difference (Beam 1$\\to$20) and directional transition counts. Pearson $r$ shown; $p < 0.001$ marked with $\\dagger$.\",\n",
    "    label=\"tab:reds_direction_compact\",\n",
    "    multicolumn=True,\n",
    "    multicolumn_format='c',\n",
    "    longtable=False\n",
    ")\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1319d2-1a2d-4db4-9240-e6fc8544cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from math import atan2, degrees\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def dfs_all_nodes(node):\n",
    "    nodes = [node]\n",
    "    for child in node.children:\n",
    "        nodes.extend(dfs_all_nodes(child))\n",
    "    return nodes\n",
    "\n",
    "def bbox_center(bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    return (x_min + x_max) / 2, (y_min + y_max) / 2\n",
    "\n",
    "def classify_8_directions(dx, dy):\n",
    "    angle = (degrees(atan2(dy, dx)) + 360) % 360\n",
    "    if (337.5 <= angle < 360) or (0 <= angle < 22.5):\n",
    "        return \"右\"\n",
    "    elif 22.5 <= angle < 67.5:\n",
    "        return \"右下\"\n",
    "    elif 67.5 <= angle < 112.5:\n",
    "        return \"下\"\n",
    "    elif 112.5 <= angle < 157.5:\n",
    "        return \"左下\"\n",
    "    elif 157.5 <= angle < 202.5:\n",
    "        return \"左\"\n",
    "    elif 202.5 <= angle < 247.5:\n",
    "        return \"左上\"\n",
    "    elif 247.5 <= angle < 292.5:\n",
    "        return \"上\"\n",
    "    elif 292.5 <= angle < 337.5:\n",
    "        return \"右上\"\n",
    "    else:\n",
    "        return \"不明\"\n",
    "\n",
    "direction_types = [\"右\", \"右下\", \"下\", \"左下\", \"左\", \"左上\", \"上\", \"右上\"]\n",
    "records = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in methods:\n",
    "        key1 = (backbone, method, 1)\n",
    "        key20 = (backbone, method, 20)\n",
    "\n",
    "        if key1 not in all_preds_dict or key20 not in all_preds_dict:\n",
    "            print(f\"[WARN] Missing: {key1} or {key20}\")\n",
    "            continue\n",
    "\n",
    "        preds1 = all_preds_dict[key1]\n",
    "        preds20 = all_preds_dict[key20]\n",
    "\n",
    "        map1 = {p[\"file_name\"]: p for p in preds1}\n",
    "        map20 = {p[\"file_name\"]: p for p in preds20}\n",
    "        common_files = set(map1) & set(map20)\n",
    "\n",
    "        # 各方向に対する正誤のカウント（A, B, C, D）\n",
    "        direction_stats = {d: {\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0} for d in direction_types}\n",
    "\n",
    "        for fname in common_files:\n",
    "            gt = map1[fname][\"gt_tree\"]\n",
    "            pred1 = map1[fname][\"pred_tree\"]\n",
    "            pred20 = map20[fname][\"pred_tree\"]\n",
    "\n",
    "            gt_nodes = [n for n in dfs_all_nodes(gt) if n.category != -1]\n",
    "            if len(gt_nodes) < 2:\n",
    "                continue\n",
    "\n",
    "            pred1_nodes = [n for n in dfs_all_nodes(pred1) if n.category != -1]\n",
    "            pred20_nodes = [n for n in dfs_all_nodes(pred20) if n.category != -1]\n",
    "            pred1_edges = set((n1.label, n2.label) for n1, n2 in zip(pred1_nodes, pred1_nodes[1:]))\n",
    "            pred20_edges = set((n1.label, n2.label) for n1, n2 in zip(pred20_nodes, pred20_nodes[1:]))\n",
    "\n",
    "            for i in range(len(gt_nodes) - 1):\n",
    "                n1, n2 = gt_nodes[i], gt_nodes[i + 1]\n",
    "                x1, y1 = bbox_center(n1.bbox)\n",
    "                x2, y2 = bbox_center(n2.bbox)\n",
    "                dx, dy = x2 - x1, y2 - y1\n",
    "                direction = classify_8_directions(dx, dy)\n",
    "                if direction not in direction_types:\n",
    "                    continue\n",
    "\n",
    "                edge = (n1.label, n2.label)\n",
    "                correct1 = edge in pred1_edges\n",
    "                correct20 = edge in pred20_edges\n",
    "\n",
    "                if correct1 and correct20:\n",
    "                    direction_stats[direction][\"A\"] += 1\n",
    "                elif correct1 and not correct20:\n",
    "                    direction_stats[direction][\"B\"] += 1\n",
    "                elif not correct1 and correct20:\n",
    "                    direction_stats[direction][\"C\"] += 1\n",
    "                else:\n",
    "                    direction_stats[direction][\"D\"] += 1\n",
    "\n",
    "        # 精度と有意性のまとめ\n",
    "        for d in direction_types:\n",
    "            A = direction_stats[d][\"A\"]\n",
    "            B = direction_stats[d][\"B\"]\n",
    "            C = direction_stats[d][\"C\"]\n",
    "            D = direction_stats[d][\"D\"]\n",
    "            total = A + B + C + D\n",
    "            if total == 0:\n",
    "                continue\n",
    "            acc1 = (A + B) / total\n",
    "            acc20 = (A + C) / total\n",
    "            delta = acc20 - acc1\n",
    "\n",
    "            # McNemar検定\n",
    "            try:\n",
    "                table = [[A, B], [C, D]]\n",
    "                res = mcnemar(table, exact=True)\n",
    "                p_val = res.pvalue\n",
    "            except Exception as e:\n",
    "                p_val = None\n",
    "                print(f\"[WARN] McNemar failed: {backbone}, {method}, {d}: {e}\")\n",
    "\n",
    "            records.append({\n",
    "                \"Backbone\": backbone,\n",
    "                \"Method\": method,\n",
    "                \"Direction\": d,\n",
    "                \"Accuracy@1\": acc1,\n",
    "                \"Accuracy@20\": acc20,\n",
    "                \"ΔAccuracy\": delta,\n",
    "                \"p-value\": p_val\n",
    "            })\n",
    "\n",
    "# --- DataFrame化 ---\n",
    "df = pd.DataFrame(records)\n",
    "df[\"acc_str\"] = df.apply(\n",
    "    lambda row: (\n",
    "        f\"\\\\textbf{{{row['Accuracy@20']*100:.1f}}} ({row['ΔAccuracy']*100:+.1f})\"\n",
    "        if row[\"p-value\"] is not None and row[\"p-value\"] < 0.05\n",
    "        else f\"{row['Accuracy@20']*100:.1f} ({row['ΔAccuracy']*100:+.1f})\"\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# --- ピボット整形 ---\n",
    "df_pivot = df.pivot(index=[\"Backbone\", \"Method\"], columns=\"Direction\", values=\"acc_str\").reset_index()\n",
    "ordered_cols = [\"Backbone\", \"Method\"] + direction_types\n",
    "for d in direction_types:\n",
    "    if d not in df_pivot.columns:\n",
    "        df_pivot[d] = \"\"\n",
    "df_pivot = df_pivot[ordered_cols]\n",
    "\n",
    "# --- 表示 ---\n",
    "# print(\"\\n=== 読み順方向別 accuracy@20 (+Δ) [p<.05 で太字] ===\")\n",
    "# print(df_pivot.to_string(index=False))\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"ll\" + \"c\" * len(direction_types),\n",
    "    caption=r\"Accuracy@20 per DFS reading-order direction, with improvement from Beam 1. Values in bold are statistically significant ($p < 0.05$) under McNemar's test.\",\n",
    "    label=\"tab:reading_order_directional_accuracy\"\n",
    ")\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)\n",
    "\n",
    "def print_significant_directions(df):\n",
    "    print(\"\\n=== 有意差ありの方向 (p < 0.05) ===\")\n",
    "    for (backbone, method), group in df.groupby([\"Backbone\", \"Method\"]):\n",
    "        sig_dirs = []\n",
    "        for _, row in group.iterrows():\n",
    "            direction = row[\"Direction\"]\n",
    "            p = row[\"p-value\"]\n",
    "            if p is not None and p < 0.05:\n",
    "                sig_dirs.append(direction)\n",
    "        mark = \"✔\" * len(sig_dirs) if sig_dirs else \"×\"\n",
    "        print(f\"[{backbone:>25} | {method:<20}] {mark} {', '.join(sig_dirs) if sig_dirs else '(なし)'}\")\n",
    "\n",
    "print_significant_directions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda5401-f594-474a-88e3-0b8ea8332e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backbone 表示名マップ\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "\n",
    "# 方向の表示順とラベル\n",
    "direction_display_order = [\n",
    "    (\"右\", \"Right\"),\n",
    "    (\"右下\", \"Bottom-Right\"),\n",
    "    (\"下\", \"Bottom\"),\n",
    "    (\"左下\", \"Bottom-Left\"),\n",
    "    (\"左\", \"Left\"),\n",
    "    (\"左上\", \"Top-Left\"),\n",
    "    (\"上\", \"Top\"),\n",
    "    (\"右上\", \"Top-Right\"),\n",
    "]\n",
    "\n",
    "# DRGG-BEBS = DRGGBBoxEmbTFEnc のみ抽出\n",
    "df_bebs = df[df[\"Method\"] == \"DRGGBBoxEmbTFEnc\"].copy()\n",
    "df_bebs[\"BackboneDisplay\"] = df_bebs[\"Backbone\"].map(backbone_name_map)\n",
    "\n",
    "# LaTeX 出力生成\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{l|rrrrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = (\n",
    "    r\"\\multicolumn{1}{l}{Backbone} & \" +\n",
    "    \" & \".join([rf\"\\multicolumn{{1}}{{l}}{{{name}}}\" for _, name in direction_display_order]) +\n",
    "    r\" \\\\\"\n",
    ")\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for bname in [\"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"]:\n",
    "    rows = df_bebs[df_bebs[\"BackboneDisplay\"] == bname]\n",
    "    if rows.empty:\n",
    "        continue\n",
    "    values = []\n",
    "    for jp_name, _ in direction_display_order:\n",
    "        row = rows[rows[\"Direction\"] == jp_name]\n",
    "        if row.empty:\n",
    "            values.append(\"\")  # データがない方向\n",
    "        else:\n",
    "            acc20 = row[\"Accuracy@20\"].values[0] * 100\n",
    "            delta = row[\"ΔAccuracy\"].values[0] * 100\n",
    "            sig = (row[\"p-value\"].values[0] < 0.05) if row[\"p-value\"].notna().values[0] else False\n",
    "            star = r\"$^\\star$\" if sig else \"\"\n",
    "            values.append(f\"{acc20:.1f}\\\\ ({delta:+.1f}){star}\")\n",
    "    lines.append(f\"{bname:<15} & \" + \" & \".join(values) + r\" \\\\\")\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# 出力\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54ff48-b1d3-4531-8ddb-46d4ea1b5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表示名マッピング\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "\n",
    "# 表示順と方向ラベル\n",
    "direction_display_order = [\n",
    "    (\"右\", \"Right\"),\n",
    "    (\"右下\", \"Bottom-Right\"),\n",
    "    (\"下\", \"Bottom\"),\n",
    "    (\"左下\", \"Bottom-Left\"),\n",
    "    (\"左\", \"Left\"),\n",
    "    (\"左上\", \"Top-Left\"),\n",
    "    (\"上\", \"Top\"),\n",
    "    (\"右上\", \"Top-Right\"),\n",
    "]\n",
    "\n",
    "# Method と Beam Width から Decoder 表示名を決定\n",
    "def get_decoder_name(method: str, beam_width: int) -> str:\n",
    "    if method == \"DRGG\" and beam_width == 20:\n",
    "        return \"DRGG-BS\"\n",
    "    elif method == \"DRGGBBoxEmbTFEnc\" and beam_width == 20:\n",
    "        return \"DRGG-BEBS\"\n",
    "    else:\n",
    "        return None  # 無視対象\n",
    "\n",
    "# df（元データ）にDecoder名・Backbone表示名を追加\n",
    "df[\"Decoder\"] = df.apply(\n",
    "    lambda row: get_decoder_name(row[\"Method\"], 20), axis=1\n",
    ")\n",
    "df[\"BackboneDisplay\"] = df[\"Backbone\"].map(backbone_name_map)\n",
    "df_filtered = df[df[\"Decoder\"].notnull()].copy()\n",
    "\n",
    "# LaTeX行生成\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{ll|rrrrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = (\n",
    "    r\"\\multicolumn{1}{l}{Backbone} & \" +\n",
    "    r\"\\multicolumn{1}{l}{Decoder} & \" +\n",
    "    \" & \".join([rf\"\\multicolumn{{1}}{{l}}{{{label}}}\" for _, label in direction_display_order]) +\n",
    "    r\" \\\\\"\n",
    ")\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for bname in [\"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"]:\n",
    "    group = df_filtered[df_filtered[\"BackboneDisplay\"] == bname]\n",
    "    if group.empty:\n",
    "        continue\n",
    "    group = group.set_index(\"Decoder\")\n",
    "    decoders = [\"DRGG-BS\", \"DRGG-BEBS\"]\n",
    "    for i, decoder in enumerate(decoders):\n",
    "        row_group = group.loc[decoder] if decoder in group.index else None\n",
    "        if row_group is None:\n",
    "            continue\n",
    "        row_data = df_filtered[\n",
    "            (df_filtered[\"BackboneDisplay\"] == bname) &\n",
    "            (df_filtered[\"Decoder\"] == decoder)\n",
    "        ]\n",
    "        vals = []\n",
    "        for jp_dir, _ in direction_display_order:\n",
    "            row = row_data[row_data[\"Direction\"] == jp_dir]\n",
    "            if row.empty:\n",
    "                vals.append(\"\")\n",
    "                continue\n",
    "            acc = row[\"Accuracy@20\"].values[0] * 100\n",
    "            delta = row[\"ΔAccuracy\"].values[0] * 100\n",
    "            sig = row[\"p-value\"].values[0] < 0.05 if row[\"p-value\"].notna().values[0] else False\n",
    "            delta_str = f\"({delta:+.1f})\" + (r\"$^\\star$\" if sig else \"\")\n",
    "            vals.append(f\"{acc:.1f} {delta_str}\")\n",
    "        \n",
    "        if i == 0:\n",
    "            # 最初の行：Backbone 表示あり\n",
    "            lines.append(rf\"\\multirow{{2}}{{*}}{{{bname}}} & {decoder} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "        else:\n",
    "            # 2行目：空白にして & 開始\n",
    "            lines.append(rf\"    & {decoder} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "\n",
    "    if bname != \"InternImage\":\n",
    "        lines.append(r\"\\midrule\")\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353692e-de29-4e4a-b05f-31abb4f62e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "\n",
    "# 日本語→英語対応表\n",
    "jp_to_en = {\n",
    "    \"右\": \"Right\",\n",
    "    \"右下\": \"Bottom-Right\",\n",
    "    \"下\": \"Bottom\",\n",
    "    \"左下\": \"Bottom-Left\",\n",
    "    \"左\": \"Left\",\n",
    "    \"左上\": \"Top-Left\",\n",
    "    \"上\": \"Top\",\n",
    "    \"右上\": \"Top-Right\"\n",
    "}\n",
    "direction_types = list(jp_to_en.keys())\n",
    "direction_types_en = [jp_to_en[d] for d in direction_types]\n",
    "\n",
    "# バックボーンごとの混同行列カウント用\n",
    "confusion_counts_per_backbone = {}\n",
    "\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "methods = [\"DRGGBBoxEmbTFEnc\"]\n",
    "\n",
    "mispred_rates = []  # 各backboneごとの割合記録\n",
    "\n",
    "def truncate_tree_at_node(root: TreeNode, stop_label: str) -> TreeNode | None:\n",
    "    \"\"\"\n",
    "    pred_tree を DFS 順に辿り、stop_label に達したらそれ以降を切り落とした部分木を返す。\n",
    "    \"\"\"\n",
    "    stopped = False  # 単なるフラグ\n",
    "\n",
    "    def dfs(node: TreeNode) -> TreeNode | None:\n",
    "        nonlocal stopped  # ← これだけでOK\n",
    "        if stopped:\n",
    "            return None\n",
    "        if node.label == stop_label:\n",
    "            stopped = True\n",
    "            return None\n",
    "\n",
    "        new_node = TreeNode(node.id, node.label, node.bbox, node.category)\n",
    "        for child in node.children:\n",
    "            if stopped:\n",
    "                break\n",
    "            child_copy = dfs(child)\n",
    "            if child_copy:\n",
    "                new_node.children.append(child_copy)\n",
    "        return new_node\n",
    "\n",
    "    return dfs(root)\n",
    "\n",
    "next_status_counts = defaultdict(lambda: [0, 0])\n",
    "\n",
    "for backbone in backbones:\n",
    "    confusion_counts = defaultdict(Counter)\n",
    "    correct_preds = 0\n",
    "    mispreds = 0\n",
    "\n",
    "    for method in methods:\n",
    "        key20 = (backbone, method, 20)\n",
    "        if key20 not in all_preds_dict:\n",
    "            print(f\"[WARN] Missing: {key20}\")\n",
    "            continue\n",
    "\n",
    "        preds20 = all_preds_dict[key20]\n",
    "        for entry in preds20:\n",
    "            gt = entry[\"gt_tree\"]\n",
    "            pred = entry[\"pred_tree\"]\n",
    "\n",
    "            gt_nodes = [n for n in dfs_all_nodes(gt) if n.category != -1]\n",
    "            pred_nodes = [n for n in dfs_all_nodes(pred) if n.category != -1]\n",
    "            pred_id2node = {n.label: n for n in pred_nodes}\n",
    "\n",
    "            pred_edges = list(zip(pred_nodes[:-1], pred_nodes[1:]))\n",
    "            pred_next_map = {n1.label: n2 for n1, n2 in pred_edges}\n",
    "\n",
    "            for i in range(len(gt_nodes) - 1):\n",
    "                n1, n2 = gt_nodes[i], gt_nodes[i + 1]\n",
    "                x1, y1 = bbox_center(n1.bbox)\n",
    "                x2, y2 = bbox_center(n2.bbox)\n",
    "                true_dir = classify_8_directions(x2 - x1, y2 - y1)\n",
    "\n",
    "                pred_next = pred_next_map.get(n1.label, None)\n",
    "                if pred_next is None:\n",
    "                    continue\n",
    "\n",
    "                if pred_next.label == n2.label:\n",
    "                    correct_preds += 1\n",
    "                    continue\n",
    "\n",
    "                px, py = bbox_center(pred_next.bbox)\n",
    "                pred_dir = classify_8_directions(px - x1, py - y1)\n",
    "\n",
    "                confusion_counts[true_dir][pred_dir] += 1\n",
    "                mispreds += 1\n",
    "\n",
    "                # 部分木構築\n",
    "                partial_tree = truncate_tree_at_node(pred, n1.label)\n",
    "                all_labels_in_tree = set(n.label for n in dfs_all_nodes(partial_tree))\n",
    "\n",
    "                if n2.label not in all_labels_in_tree:\n",
    "                    next_status_counts[backbone][0] += 1  # 選択可能\n",
    "                else:\n",
    "                    next_status_counts[backbone][1] += 1  # 選択不可能\n",
    "\n",
    "    # 保存\n",
    "    df = pd.DataFrame.from_dict(confusion_counts, orient=\"index\", columns=direction_types).fillna(0).astype(int)\n",
    "    df = df.reindex(index=direction_types, columns=direction_types)\n",
    "    df.index = [jp_to_en[idx] for idx in df.index]\n",
    "    df.columns = [jp_to_en[col] for col in df.columns]\n",
    "    confusion_counts_per_backbone[backbone] = df\n",
    "\n",
    "    total = correct_preds + mispreds\n",
    "    if total > 0:\n",
    "        rate = 100 * mispreds / total\n",
    "        mispred_rates.append(rate)\n",
    "        print(f\"[{backbone}] mispredicted割合: {rate:.2f}%  ({mispreds} / {total})\")\n",
    "    else:\n",
    "        print(f\"[{backbone}] 有効な方向予測が存在しません\")\n",
    "\n",
    "\n",
    "# 正規化と平均混同行列の計算\n",
    "normalized_dfs = []\n",
    "for df in confusion_counts_per_backbone.values():\n",
    "    normalized = df.div(df.sum(axis=1), axis=0).fillna(0)\n",
    "    normalized_dfs.append(normalized)\n",
    "\n",
    "mean_confusion = sum(normalized_dfs) / len(normalized_dfs)\n",
    "\n",
    "# # 出力\n",
    "# print(\"\\n=== 読み順方向混同行列の割合平均（GT: 縦軸, beam20予測: 横軸）===\")\n",
    "# print(mean_confusion.round(3))\n",
    "\n",
    "# 平均出力\n",
    "if mispred_rates:\n",
    "    mean_rate = sum(mispred_rates) / len(mispred_rates)\n",
    "    print(f\"\\n=== mispredicted割合（backbone平均）: {mean_rate:.2f}% ===\")\n",
    "else:\n",
    "    print(\"\\n=== mispredicted割合の平均を計算できません（データなし） ===\")\n",
    "\n",
    "print(\"\\n=== 正解次ノードの構築時点の分類（backboneごと） ===\")\n",
    "avg_ratios = [0, 0]\n",
    "valid_backbones = 0\n",
    "for backbone, (selectable, not_selectable) in next_status_counts.items():\n",
    "    total = selectable + not_selectable\n",
    "    if total == 0:\n",
    "        continue\n",
    "    r1 = selectable / total * 100\n",
    "    r2 = not_selectable / total * 100\n",
    "    print(f\"[{backbone}]\")\n",
    "    print(f\"  1. 選択可能  : {selectable} ({r1:.2f}%)\")\n",
    "    print(f\"  2. 選択不可能: {not_selectable} ({r2:.2f}%)\")\n",
    "    avg_ratios[0] += r1\n",
    "    avg_ratios[1] += r2\n",
    "    valid_backbones += 1\n",
    "\n",
    "if valid_backbones > 0:\n",
    "    print(\"\\n=== 分類割合（backbone平均） ===\")\n",
    "    print(f\"  1. 選択可能: {avg_ratios[0]/valid_backbones:.2f}%\")\n",
    "    print(f\"  2. 選択不可能: {avg_ratios[1]/valid_backbones:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n=== データなし：backbone 平均は計算不可 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2c411-91d4-43ed-ade6-723e7eff9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# direction_types と対応する英語表現\n",
    "direction_types_en = [\"Right\", \"Bottom-Right\", \"Bottom\", \"Bottom-Left\",\n",
    "                      \"Left\", \"Top-Left\", \"Top\", \"Top-Right\"]\n",
    "\n",
    "# ヒートマップ描画（割合平均）\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.heatmap(\n",
    "    mean_confusion,\n",
    "    # annot=True,\n",
    "    # fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=direction_types_en,\n",
    "    yticklabels=direction_types_en\n",
    ")\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "plt.xlabel(\"Direction of Mispredicted BBox\", fontsize=18)\n",
    "plt.ylabel(\"Direction of GT BBox\", fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=18)\n",
    "# plt.title(\"Average Confusion Matrix of Reading Order Directions (beam20)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/reading_order_error_direction.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"./figures/reading_order_error_direction.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5411d-99a9-43a7-af08-40af4ba88070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- bbox 辺情報を得る関数 ---\n",
    "def bbox_edges(bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    return {\n",
    "        \"left\": x_min,\n",
    "        \"right\": x_max,\n",
    "        \"top\": y_min,\n",
    "        \"bottom\": y_max,\n",
    "        \"center_x\": (x_min + x_max) / 2,\n",
    "        \"center_y\": (y_min + y_max) / 2,\n",
    "    }\n",
    "\n",
    "# --- パターンキー（簡潔な方向ペア表記） ---\n",
    "ud_keys = [\"上下:下→上\", \"上下:上→下\"]\n",
    "lr_keys = [\"左右:右→左\", \"左右:左→右\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in methods:\n",
    "        key1 = (backbone, method, 1)\n",
    "        key20 = (backbone, method, 20)\n",
    "\n",
    "        if key1 not in all_preds_dict or key20 not in all_preds_dict:\n",
    "            print(f\"[WARN] Missing preds for {backbone}-{method}\")\n",
    "            continue\n",
    "\n",
    "        preds1 = all_preds_dict[key1]\n",
    "        preds20 = all_preds_dict[key20]\n",
    "\n",
    "        # --- REDS差分計算 ---\n",
    "        file_to_reds_diff = {}\n",
    "        for p1 in preds1:\n",
    "            fname = p1[\"file_name\"]\n",
    "            reds1 = p1[\"reds\"]\n",
    "            p20 = next((p for p in preds20 if p[\"file_name\"] == fname), None)\n",
    "            if p20 and \"reds\" in p20:\n",
    "                file_to_reds_diff[fname] = p20[\"reds\"] - reds1\n",
    "\n",
    "        # --- バックワードパターンカウント ---\n",
    "        file_to_backward_counts = defaultdict(Counter)\n",
    "        for p1 in preds1:\n",
    "            fname = p1[\"file_name\"]\n",
    "            if fname not in file_to_reds_diff or \"pred_tree\" not in p1:\n",
    "                continue\n",
    "\n",
    "            root = p1[\"pred_tree\"]\n",
    "            ordered = dfs_all_nodes(root)\n",
    "            nodes = [n for n in ordered if n.category != -1]\n",
    "            if len(nodes) < 3:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(nodes) - 2):\n",
    "                n1, n2, n3 = nodes[i], nodes[i+1], nodes[i+2]\n",
    "                b1, b2, b3 = bbox_edges(n1.bbox), bbox_edges(n2.bbox), bbox_edges(n3.bbox)\n",
    "\n",
    "                dx1 = b2[\"center_x\"] - b1[\"center_x\"]\n",
    "                dx2 = b3[\"center_x\"] - b2[\"center_x\"]\n",
    "                dy1 = b2[\"center_y\"] - b1[\"center_y\"]\n",
    "                dy2 = b3[\"center_y\"] - b2[\"center_y\"]\n",
    "\n",
    "                if dy1 > 0 and dy2 < 0 and b2[\"center_y\"] > b1[\"bottom\"] and b3[\"center_y\"] < b2[\"top\"]:\n",
    "                    file_to_backward_counts[fname][\"上下:下→上\"] += 1\n",
    "                elif dy1 < 0 and dy2 > 0 and b2[\"center_y\"] < b1[\"top\"] and b3[\"center_y\"] > b2[\"bottom\"]:\n",
    "                    file_to_backward_counts[fname][\"上下:上→下\"] += 1\n",
    "                if dx1 > 0 and dx2 < 0 and b2[\"center_x\"] > b1[\"right\"] and b3[\"center_x\"] < b2[\"left\"]:\n",
    "                    file_to_backward_counts[fname][\"左右:左→右\"] += 1\n",
    "                elif dx1 < 0 and dx2 > 0 and b2[\"center_x\"] < b1[\"left\"] and b3[\"center_x\"] > b2[\"right\"]:\n",
    "                    file_to_backward_counts[fname][\"左右:右→左\"] += 1\n",
    "\n",
    "        # --- 総和カウント ---\n",
    "        for fname in file_to_backward_counts:\n",
    "            total = sum(file_to_backward_counts[fname].get(p, 0) for p in ud_keys + lr_keys)\n",
    "            file_to_backward_counts[fname][\"総バックワード\"] = total\n",
    "\n",
    "        # --- 相関計算 ---\n",
    "        for pattern in ud_keys + lr_keys + [\"総バックワード\"]:\n",
    "            reds, counts = [], []\n",
    "            for fname in file_to_reds_diff:\n",
    "                if fname in file_to_backward_counts:\n",
    "                    reds.append(file_to_reds_diff[fname])\n",
    "                    counts.append(file_to_backward_counts[fname].get(pattern, 0))\n",
    "            if len(reds) >= 2:\n",
    "                r, p = pearsonr(counts, reds)\n",
    "                results.append({\n",
    "                    \"Backbone\": backbone,\n",
    "                    \"Method\": method,\n",
    "                    \"Pattern\": pattern,\n",
    "                    \"Pearson r\": r,\n",
    "                    \"p-value\": p\n",
    "                })\n",
    "\n",
    "# --- 結果 DataFrame ---\n",
    "df_corr = pd.DataFrame(results)\n",
    "\n",
    "# print(\"=== 相関（バックワードパターン） ===\")\n",
    "# print(df_corr.to_string(index=False))\n",
    "\n",
    "# # --- LaTeX 出力 ---\n",
    "# latex = df_corr.to_latex(\n",
    "#     index=False,\n",
    "#     float_format=\"%.4f\",\n",
    "#     caption=\"Correlation between REDS difference (Beam 1→20) and backward reading patterns per image.\",\n",
    "#     label=\"tab:reds_backward_corr\"\n",
    "# )\n",
    "# print(\"\\n=== LaTeX 出力 ===\")\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10941159-62ea-4bb6-952d-34bdcbdfff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- r†形式で整形 ---\n",
    "def format_r_dagger(row):\n",
    "    r_val = f\"{row['Pearson r']:.3f}\"\n",
    "    return f\"{r_val}$\\\\dagger$\" if row[\"p-value\"] < 0.001 else r_val\n",
    "\n",
    "df_corr[\"r(p)\"] = df_corr.apply(format_r_dagger, axis=1)\n",
    "\n",
    "# --- ピボット：Metric列を展開し、方向ペアで一行表示に整形 ---\n",
    "df_pivot = df_corr.pivot(index=[\"Backbone\", \"Method\"], columns=\"Pattern\", values=\"r(p)\").reset_index()\n",
    "\n",
    "# --- 明示的なカラム順（2方向ペア＋合計） ---\n",
    "ordered_cols = [\"Backbone\", \"Method\",\n",
    "                \"上下:下→上\", \"上下:上→下\",\n",
    "                \"左右:右→左\", \"左右:左→右\",\n",
    "                \"総バックワード\"]\n",
    "\n",
    "# 欠損を含む列を補完（評価漏れ対策）\n",
    "for col in ordered_cols:\n",
    "    if col not in df_pivot.columns:\n",
    "        df_pivot[col] = \"\"\n",
    "\n",
    "df_pivot = df_pivot[ordered_cols]\n",
    "\n",
    "# --- LaTeX書き出し ---\n",
    "latex_table = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"ll\" + \"r\" * (len(ordered_cols) - 2),\n",
    "    caption=r\"Correlation between REDS difference (Beam 1$\\to$20) and backward reading patterns. Pearson $r$ shown; $p < 0.001$ marked with $\\dagger$.\",\n",
    "    label=\"tab:reds_backward_compact\",\n",
    "    multicolumn=True,\n",
    "    multicolumn_format='c',\n",
    "    longtable=False\n",
    ")\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4f7b3-f568-4655-bf3d-ead01303aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# バックワード分類キー（上下/左右それぞれ）\n",
    "pattern_keys = [\n",
    "    \"上下:下-上\", \"上下:上-下\", \"上下:その他\",\n",
    "    \"左右:右-左\", \"左右:左-右\", \"左右:その他\"\n",
    "]\n",
    "\n",
    "records = []\n",
    "\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "methods = [\"DRGG\", \"DRGGBBoxEmbTFEnc\"]\n",
    "beam_widths = [1, 20]\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in methods:\n",
    "        key1 = (backbone, method, 1)\n",
    "        key20 = (backbone, method, 20)\n",
    "\n",
    "        if key1 not in all_preds_dict or key20 not in all_preds_dict:\n",
    "            print(f\"[WARN] Missing: {key1} or {key20}\")\n",
    "            continue\n",
    "\n",
    "        preds1 = all_preds_dict[key1]\n",
    "        preds20 = all_preds_dict[key20]\n",
    "\n",
    "        map1 = {p[\"file_name\"]: p for p in preds1}\n",
    "        map20 = {p[\"file_name\"]: p for p in preds20}\n",
    "        common_files = set(map1) & set(map20)\n",
    "\n",
    "        stats = {k: [0, 0, 0] for k in pattern_keys}  # [total, correct@1, correct@20]\n",
    "\n",
    "        for fname in common_files:\n",
    "            gt = map1[fname][\"gt_tree\"]\n",
    "            pred1 = map1[fname][\"pred_tree\"]\n",
    "            pred20 = map20[fname][\"pred_tree\"]\n",
    "\n",
    "            ordered_gt = dfs_all_nodes(gt)\n",
    "            nodes = [n for n in ordered_gt if n.category != -1]\n",
    "            if len(nodes) < 3:\n",
    "                continue\n",
    "\n",
    "            pred1_nodes = [n for n in dfs_all_nodes(pred1) if n.category != -1]\n",
    "            pred20_nodes = [n for n in dfs_all_nodes(pred20) if n.category != -1]\n",
    "\n",
    "            pred1_edges = set((n1.label, n2.label) for n1, n2 in zip(pred1_nodes, pred1_nodes[1:]))\n",
    "            pred20_edges = set((n1.label, n2.label) for n1, n2 in zip(pred20_nodes, pred20_nodes[1:]))\n",
    "\n",
    "            for i in range(len(nodes) - 2):\n",
    "                n1, n2, n3 = nodes[i], nodes[i + 1], nodes[i + 2]\n",
    "                b1 = bbox_edges(n1.bbox)\n",
    "                b2 = bbox_edges(n2.bbox)\n",
    "                b3 = bbox_edges(n3.bbox)\n",
    "\n",
    "                dx1 = b2[\"center_x\"] - b1[\"center_x\"]\n",
    "                dx2 = b3[\"center_x\"] - b2[\"center_x\"]\n",
    "                dy1 = b2[\"center_y\"] - b1[\"center_y\"]\n",
    "                dy2 = b3[\"center_y\"] - b2[\"center_y\"]\n",
    "\n",
    "                edge_pair = [(n1.label, n2.label), (n2.label, n3.label)]\n",
    "                is_correct1 = all(e in pred1_edges for e in edge_pair)\n",
    "                is_correct20 = all(e in pred20_edges for e in edge_pair)\n",
    "\n",
    "                # --- 上下方向 ---\n",
    "                if dy1 > 0 and dy2 < 0:\n",
    "                    if b2[\"center_y\"] > b1[\"bottom\"] and b3[\"center_y\"] < b2[\"top\"]:\n",
    "                        key = \"上下:下-上\"\n",
    "                    else:\n",
    "                        key = \"上下:その他\"\n",
    "                elif dy1 < 0 and dy2 > 0:\n",
    "                    if b2[\"center_y\"] < b1[\"top\"] and b3[\"center_y\"] > b2[\"bottom\"]:\n",
    "                        key = \"上下:上-下\"\n",
    "                    else:\n",
    "                        key = \"上下:その他\"\n",
    "                else:\n",
    "                    key = \"上下:その他\"\n",
    "                stats[key][0] += 1\n",
    "                stats[key][1] += int(is_correct1)\n",
    "                stats[key][2] += int(is_correct20)\n",
    "\n",
    "                # --- 左右方向 ---\n",
    "                if dx1 > 0 and dx2 < 0:\n",
    "                    if b2[\"center_x\"] > b1[\"right\"] and b3[\"center_x\"] < b2[\"left\"]:\n",
    "                        key = \"左右:右-左\"\n",
    "                    else:\n",
    "                        key = \"左右:その他\"\n",
    "                elif dx1 < 0 and dx2 > 0:\n",
    "                    if b2[\"center_x\"] < b1[\"left\"] and b3[\"center_x\"] > b2[\"right\"]:\n",
    "                        key = \"左右:左-右\"\n",
    "                    else:\n",
    "                        key = \"左右:その他\"\n",
    "                else:\n",
    "                    key = \"左右:その他\"\n",
    "                stats[key][0] += 1\n",
    "                stats[key][1] += int(is_correct1)\n",
    "                stats[key][2] += int(is_correct20)\n",
    "\n",
    "        # --- 整形 ---\n",
    "        row = {\"Backbone\": backbone, \"Method\": method}\n",
    "        for k in pattern_keys:\n",
    "            total, c1, c20 = stats[k]\n",
    "            if total == 0:\n",
    "                row[k] = \"\"\n",
    "            else:\n",
    "                acc1 = c1 / total * 100\n",
    "                acc20 = c20 / total * 100\n",
    "                delta = acc20 - acc1\n",
    "                row[k] = f\"{acc20:.1f} ({delta:+.1f})\"\n",
    "        records.append(row)\n",
    "\n",
    "# --- 出力 ---\n",
    "df = pd.DataFrame(records)\n",
    "df = df[[\"Backbone\", \"Method\"] + pattern_keys]\n",
    "\n",
    "print(\"\\n=== GTトリプレット方向別 accuracy@20 (+Δ) ===\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"ll\" + \"c\" * len(pattern_keys),\n",
    "    caption=r\"Accuracy@20 per GT reading-order triplet direction, with improvement from Beam 1. Format: acc20 (+Δ).\",\n",
    "    label=\"tab:gt_triplet_directional_accuracy\"\n",
    ")\n",
    "print(\"\\n=== LaTeX ===\")\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00a4a2-7321-4cd0-adef-8aede4cf5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "\n",
    "# パターンキー\n",
    "pattern_keys_v = [\"上下:下-上\", \"上下:上-下\", \"上下:その他\"]\n",
    "pattern_keys_h = [\"左右:右-左\", \"左右:左-右\", \"左右:その他\"]\n",
    "\n",
    "confusions_per_backbone = {\n",
    "    \"上下\": {b: defaultdict(Counter) for b in backbones},\n",
    "    \"左右\": {b: defaultdict(Counter) for b in backbones}\n",
    "}\n",
    "\n",
    "method = \"DRGGBBoxEmbTFEnc\"\n",
    "beam_width = 20\n",
    "\n",
    "for backbone in backbones:\n",
    "    key = (backbone, method, beam_width)\n",
    "    if key not in all_preds_dict:\n",
    "        print(f\"[WARN] Missing: {key}\")\n",
    "        continue\n",
    "\n",
    "    preds = all_preds_dict[key]\n",
    "\n",
    "    for entry in preds:\n",
    "        gt = entry[\"gt_tree\"]\n",
    "        pred = entry[\"pred_tree\"]\n",
    "\n",
    "        gt_nodes = [n for n in dfs_all_nodes(gt) if n.category != -1]\n",
    "        pred_nodes = [n for n in dfs_all_nodes(pred) if n.category != -1]\n",
    "        pred_label_map = {n.label: n for n in pred_nodes}\n",
    "        pred_labels = [n.label for n in pred_nodes]\n",
    "\n",
    "        if len(gt_nodes) < 3 or len(pred_nodes) < 3:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(gt_nodes) - 2):\n",
    "            n1, n2, n3 = gt_nodes[i], gt_nodes[i+1], gt_nodes[i+2]\n",
    "\n",
    "            # --- anchor n1 が予測に含まれない場合は除外 ---\n",
    "            if n1.label not in pred_label_map:\n",
    "                continue\n",
    "            idx = pred_labels.index(n1.label)\n",
    "            if idx + 2 >= len(pred_nodes):\n",
    "                continue\n",
    "\n",
    "            n2p, n3p = pred_nodes[idx + 1], pred_nodes[idx + 2]\n",
    "\n",
    "            # --- 正解ならスキップ ---\n",
    "            if n2p.label == n2.label and n3p.label == n3.label:\n",
    "                continue\n",
    "\n",
    "            # --- bbox 中心 ---\n",
    "            def center(n): return bbox_edges(n.bbox)\n",
    "\n",
    "            # --- 上下パターン判定 ---\n",
    "            def classify_vertical(n1, n2, n3):\n",
    "                b1, b2, b3 = center(n1), center(n2), center(n3)\n",
    "                dy1 = b2[\"center_y\"] - b1[\"center_y\"]\n",
    "                dy2 = b3[\"center_y\"] - b1[\"center_y\"]\n",
    "                if dy1 > 0 and dy2 < 0 and b2[\"center_y\"] > b1[\"bottom\"] and b3[\"center_y\"] < b1[\"top\"]:\n",
    "                    return \"上下:下-上\"\n",
    "                elif dy1 < 0 and dy2 > 0 and b2[\"center_y\"] < b1[\"top\"] and b3[\"center_y\"] > b1[\"bottom\"]:\n",
    "                    return \"上下:上-下\"\n",
    "                else:\n",
    "                    return \"上下:その他\"\n",
    "\n",
    "            # --- 左右パターン判定 ---\n",
    "            def classify_horizontal(n1, n2, n3):\n",
    "                b1, b2, b3 = center(n1), center(n2), center(n3)\n",
    "                dx1 = b2[\"center_x\"] - b1[\"center_x\"]\n",
    "                dx2 = b3[\"center_x\"] - b1[\"center_x\"]\n",
    "                if dx1 > 0 and dx2 < 0 and b2[\"center_x\"] > b1[\"right\"] and b3[\"center_x\"] < b1[\"left\"]:\n",
    "                    return \"左右:右-左\"\n",
    "                elif dx1 < 0 and dx2 > 0 and b2[\"center_x\"] < b1[\"left\"] and b3[\"center_x\"] > b1[\"right\"]:\n",
    "                    return \"左右:左-右\"\n",
    "                else:\n",
    "                    return \"左右:その他\"\n",
    "\n",
    "            gt_v = classify_vertical(n1, n2, n3)\n",
    "            pred_v = classify_vertical(n1, n2p, n3p)\n",
    "            confusions_per_backbone[\"上下\"][backbone][gt_v][pred_v] += 1\n",
    "\n",
    "            gt_h = classify_horizontal(n1, n2, n3)\n",
    "            pred_h = classify_horizontal(n1, n2p, n3p)\n",
    "            confusions_per_backbone[\"左右\"][backbone][gt_h][pred_h] += 1\n",
    "\n",
    "confusion_avg = {}\n",
    "for axis, pattern_keys in [(\"上下\", pattern_keys_v), (\"左右\", pattern_keys_h)]:\n",
    "    normalized_dfs = []\n",
    "    for backbone in backbones:\n",
    "        counter = confusions_per_backbone[axis][backbone]\n",
    "        df = pd.DataFrame.from_dict(counter, orient=\"index\", columns=pattern_keys).fillna(0).astype(int)\n",
    "        df = df.reindex(index=pattern_keys, columns=pattern_keys)\n",
    "        df_norm = df.div(df.sum(axis=1), axis=0).fillna(0)\n",
    "        normalized_dfs.append(df_norm)\n",
    "    confusion_avg[axis] = sum(normalized_dfs) / len(normalized_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604783cc-09c8-457f-bac7-d0ba695c507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusions_per_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c1d53-2d87-45e9-89f6-96bde9380e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ラベル定義\n",
    "pattern_keys_v = [\"上下:下-上\", \"上下:上-下\", \"上下:その他\"]\n",
    "pattern_keys_h = [\"左右:右-左\", \"左右:左-右\", \"左右:その他\"]\n",
    "\n",
    "pattern_keys_v_en = [\"V:Down-Up\", \"V:Up-Down\", \"V:Other\"]\n",
    "pattern_keys_h_en = [\"H:Right-Left\", \"H:Left-Right\", \"H:Other\"]\n",
    "\n",
    "ja_to_en = {\n",
    "    \"上下:下-上\": \"V:Down-Up\", \"上下:上-下\": \"V:Up-Down\", \"上下:その他\": \"V:Other\",\n",
    "    \"左右:右-左\": \"H:Right-Left\", \"左右:左-右\": \"H:Other\", \"左右:左-右\": \"H:Left-Right\", \"左右:その他\": \"H:Other\"\n",
    "}\n",
    "\n",
    "for axis, keys_ja, keys_en in [(\"上下\", pattern_keys_v, pattern_keys_v_en), (\"左右\", pattern_keys_h, pattern_keys_h_en)]:\n",
    "    df = confusion_avg[axis].copy()\n",
    "    df.index = [ja_to_en[i] for i in df.index]\n",
    "    df.columns = [ja_to_en[c] for c in df.columns]\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    ax = sns.heatmap(\n",
    "        df,\n",
    "        cmap=\"Blues\",\n",
    "        cbar=True,\n",
    "        xticklabels=keys_en,\n",
    "        yticklabels=keys_en,\n",
    "        # annot=True,\n",
    "        # fmt=\".2f\"\n",
    "    )\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    plt.xlabel(\"Predicted Triplet\", fontsize=14)\n",
    "    plt.ylabel(\"GT Triplet\", fontsize=14)\n",
    "    plt.xticks(rotation=0, fontsize=18)\n",
    "    plt.yticks(rotation=0, fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    label = \"v\" if axis == \"上下\" else \"h\"\n",
    "    plt.savefig(f\"triplet_{label}_error_direction.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"triplet_{label}_error_direction.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33660b9-78ce-4a9e-bacd-ac9c1ff5b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "records = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method in [\"DRGG\", \"DRGGBBoxEmbTFEnc\"]:\n",
    "        key_1 = (backbone, method, 1)\n",
    "        key_20 = (backbone, method, 20)\n",
    "\n",
    "        if key_1 not in all_preds_dict or key_20 not in all_preds_dict:\n",
    "            continue\n",
    "\n",
    "        preds_1 = all_preds_dict[key_1]\n",
    "        preds_20 = all_preds_dict[key_20]\n",
    "\n",
    "        map_1 = {p[\"file_name\"]: p for p in preds_1}\n",
    "        map_20 = {p[\"file_name\"]: p for p in preds_20}\n",
    "        common_files = set(map_1) & set(map_20)\n",
    "\n",
    "        for fname in common_files:\n",
    "            gt = map_1[fname][\"gt_tree\"]\n",
    "            pred1 = map_1[fname][\"pred_tree\"]\n",
    "            pred2 = map_20[fname][\"pred_tree\"]\n",
    "\n",
    "            nodes = [n for n in dfs_all_nodes(gt) if n.category != -1]\n",
    "            if len(nodes) < 2:\n",
    "                continue\n",
    "\n",
    "            pred1_edges = set((n1.label, n2.label) for n1, n2 in zip(dfs_all_nodes(pred1), dfs_all_nodes(pred1)[1:]) if n1.category != -1 and n2.category != -1)\n",
    "            pred2_edges = set((n1.label, n2.label) for n1, n2 in zip(dfs_all_nodes(pred2), dfs_all_nodes(pred2)[1:]) if n1.category != -1 and n2.category != -1)\n",
    "\n",
    "            for i in range(len(nodes) - 1):\n",
    "                n1, n2 = nodes[i], nodes[i + 1]\n",
    "                x1, y1 = bbox_center(n1.bbox)\n",
    "                x2, y2 = bbox_center(n2.bbox)\n",
    "                dx = abs(x2 - x1)\n",
    "                dy = abs(y2 - y1)\n",
    "\n",
    "                if dx >= dy:\n",
    "                    dist = dx\n",
    "                    scale = max(n1.bbox[2] - n1.bbox[0], n2.bbox[2] - n2.bbox[0])  # width\n",
    "                else:\n",
    "                    dist = dy\n",
    "                    scale = max(n1.bbox[3] - n1.bbox[1], n2.bbox[3] - n2.bbox[1])  # height\n",
    "\n",
    "                if scale == 0:\n",
    "                    continue\n",
    "\n",
    "                norm_dist = dist / scale\n",
    "                edge = (n1.label, n2.label)\n",
    "                correct1 = int(edge in pred1_edges)\n",
    "                correct20 = int(edge in pred2_edges)\n",
    "\n",
    "                records.append({\n",
    "                    \"Backbone\": backbone,\n",
    "                    \"Method\": method,\n",
    "                    \"file\": fname,\n",
    "                    \"distance\": norm_dist,\n",
    "                    \"Acc@1\": correct1,\n",
    "                    \"Acc@20\": correct20,\n",
    "                    \"Diff\": correct20 - correct1\n",
    "                })\n",
    "\n",
    "# --- DataFrame化 ---\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# --- bin分割と集計 ---\n",
    "bins = [0, 1, 2, 4, 8, 16, np.inf]\n",
    "labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", \"(16, \\infty)\"]\n",
    "df[\"bin\"] = pd.cut(df[\"distance\"], bins=bins, labels=labels)\n",
    "\n",
    "grouped = df.groupby([\"Backbone\", \"Method\", \"bin\"]).agg(\n",
    "    Count=(\"Diff\", \"count\"),\n",
    "    Acc_1=(\"Acc@1\", \"mean\"),\n",
    "    Acc_20=(\"Acc@20\", \"mean\"),\n",
    "    Diff=(\"Diff\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"Acc@1 (%)\"] = (grouped[\"Acc_1\"] * 100).round(1)\n",
    "grouped[\"Acc@20 (%)\"] = (grouped[\"Acc_20\"] * 100).round(1)\n",
    "grouped[\"ΔAccuracy (%)\"] = (grouped[\"Diff\"] * 100).round(1)\n",
    "grouped[\"acc_str\"] = grouped.apply(\n",
    "    lambda row: f\"{row['Acc@20 (%)']:.1f} ({row['ΔAccuracy (%)']:+.1f})\", axis=1\n",
    ")\n",
    "\n",
    "# --- ピボット（距離binを列化） ---\n",
    "df_pivot = grouped.pivot(index=[\"Backbone\", \"Method\"], columns=\"bin\", values=\"acc_str\").reset_index()\n",
    "for b in labels:\n",
    "    if b not in df_pivot.columns:\n",
    "        df_pivot[b] = \"\"\n",
    "df_pivot = df_pivot[[\"Backbone\", \"Method\"] + labels]\n",
    "\n",
    "# --- 表示 ---\n",
    "# print(\"\\n=== 読み順構造における Beam Width の比較（手法固定） ===\")\n",
    "# print(df_pivot.to_string(index=False))\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"ll\" + \"c\" * len(labels),\n",
    "    caption=r\"Accuracy@20 per reading-order distance bin, comparing beam width 1 vs 20 (fixed method). Format: acc20 (+Δ).\",\n",
    "    label=\"tab:beam_width_reading_order_fixed_method\"\n",
    ")\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bce93-d586-4493-ac06-b7023de1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# --- 元の集計をまず行う ---\n",
    "grouped = df.groupby([\"Backbone\", \"Method\", \"bin\"]).agg(\n",
    "    Count=(\"Diff\", \"count\"),\n",
    "    Acc_1=(\"Acc@1\", \"mean\"),\n",
    "    Acc_20=(\"Acc@20\", \"mean\"),\n",
    "    Diff=(\"Diff\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"Acc@1 (%)\"] = (grouped[\"Acc_1\"] * 100).round(1)\n",
    "grouped[\"Acc@20 (%)\"] = (grouped[\"Acc_20\"] * 100).round(1)\n",
    "grouped[\"ΔAccuracy (%)\"] = (grouped[\"Diff\"] * 100).round(1)\n",
    "\n",
    "# --- McNemar検定（元の df を使って） ---\n",
    "pvals = []\n",
    "for (backbone, method, bin_label), g in df.groupby([\"Backbone\", \"Method\", \"bin\"]):\n",
    "    A = sum((g[\"Acc@1\"] == 1) & (g[\"Acc@20\"] == 1))\n",
    "    B = sum((g[\"Acc@1\"] == 1) & (g[\"Acc@20\"] == 0))\n",
    "    C = sum((g[\"Acc@1\"] == 0) & (g[\"Acc@20\"] == 1))\n",
    "    D = sum((g[\"Acc@1\"] == 0) & (g[\"Acc@20\"] == 0))\n",
    "\n",
    "    if B + C < 5:\n",
    "        p_val = None\n",
    "    else:\n",
    "        try:\n",
    "            res = mcnemar([[A, B], [C, D]], exact=True)\n",
    "            p_val = res.pvalue\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] McNemar failed: {backbone}, {method}, {bin_label}: {e}\")\n",
    "            p_val = None\n",
    "\n",
    "    pvals.append({\n",
    "        \"Backbone\": backbone,\n",
    "        \"Method\": method,\n",
    "        \"bin\": bin_label,\n",
    "        \"p-value\": p_val\n",
    "    })\n",
    "\n",
    "# --- マージして acc_str を構築 ---\n",
    "pval_df = pd.DataFrame(pvals)\n",
    "grouped = grouped.merge(pval_df, on=[\"Backbone\", \"Method\", \"bin\"], how=\"left\")\n",
    "grouped[\"acc_str\"] = grouped.apply(\n",
    "    lambda row: (\n",
    "        f\"\\\\textbf{{{row['Acc@20 (%)']:.1f}}} ({row['ΔAccuracy (%)']:+.1f})\"\n",
    "        if row[\"p-value\"] is not None and row[\"p-value\"] < 0.05\n",
    "        else f\"{row['Acc@20 (%)']:.1f} ({row['ΔAccuracy (%)']:+.1f})\"\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- ピボット ---\n",
    "df_pivot = grouped.pivot(index=[\"Backbone\", \"Method\"], columns=\"bin\", values=\"acc_str\").reset_index()\n",
    "for b in labels:\n",
    "    if b not in df_pivot.columns:\n",
    "        df_pivot[b] = \"\"\n",
    "df_pivot = df_pivot[[\"Backbone\", \"Method\"] + labels]\n",
    "\n",
    "# --- 表示 ---\n",
    "# print(\"\\n=== 読み順構造における Beam Width の比較（手法固定, 有意差は太字） ===\")\n",
    "# print(df_pivot.to_string(index=False))\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"ll\" + \"c\" * len(labels),\n",
    "    caption=r\"Accuracy@20 per reading-order distance bin, comparing beam width 1 vs 20 (fixed method). Values in bold are statistically significant ($p < 0.05$) under McNemar's test.\",\n",
    "    label=\"tab:beam_width_reading_order_fixed_method\"\n",
    ")\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21278398-b7a0-4d13-ad83-cf6b07137cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mcnemar_significance(grouped, labels):\n",
    "    print(\"\\n=== 距離ビンごとの有意差 (p < 0.05, McNemar) ===\")\n",
    "    for (backbone, method), subdf in grouped.groupby([\"Backbone\", \"Method\"]):\n",
    "        print(f\"[Backbone={backbone} | Method={method}]\")\n",
    "        line = \"  \"\n",
    "        for b in labels:\n",
    "            row = subdf[subdf[\"bin\"] == b]\n",
    "            if row.empty:\n",
    "                mark = \"－\"  # 該当なし\n",
    "            elif row.iloc[0][\"p-value\"] is not None and row.iloc[0][\"p-value\"] < 0.05:\n",
    "                mark = \"✔\"\n",
    "            else:\n",
    "                mark = \"✘\"\n",
    "            line += f\"{mark} {b:<10} \"\n",
    "        print(line)\n",
    "\n",
    "print_mcnemar_significance(grouped, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508ed7a-e236-42e0-9077-3dc4f3e35c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# --- 表示名マッピング ---\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "\n",
    "# --- DRGG-BEBS（Method == \"DRGGBBoxEmbTFEnc\"）のみ抽出 ---\n",
    "df_bebs = df_pivot[df_pivot[\"Method\"] == \"DRGGBBoxEmbTFEnc\"].copy()\n",
    "df_bebs[\"Backbone\"] = df_bebs[\"Backbone\"].map(backbone_name_map)\n",
    "\n",
    "# --- textbf 除去＋有意差マーク付加 ---\n",
    "def remove_textbf_and_add_star(cell):\n",
    "    if not isinstance(cell, str):\n",
    "        return cell\n",
    "    # \\textbf{...} (...) のときだけ $^\\star$ を追加\n",
    "    m = re.match(r\"\\\\textbf{([\\d.]+)}\\s+\\(([-+.\\d]+)\\)\", cell)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} ({m.group(2)})$^\\\\star$\"\n",
    "    # 通常の \\textbf{...} は除去だけ\n",
    "    return re.sub(r\"\\\\textbf{([^}]*)}\", r\"\\1\", cell).strip()\n",
    "\n",
    "for col in labels:\n",
    "    df_bebs[col] = df_bebs[col].apply(remove_textbf_and_add_star)\n",
    "\n",
    "# --- 出力順制御 ---\n",
    "backbone_order = [\"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"]\n",
    "df_bebs[\"Backbone\"] = pd.Categorical(df_bebs[\"Backbone\"], categories=backbone_order, ordered=True)\n",
    "df_bebs = df_bebs.sort_values(\"Backbone\")\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{l|rrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = r\"Backbone & \" + \" & \".join(labels) + r\" \\\\\"\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for _, row in df_bebs.iterrows():\n",
    "    row_vals = [row[l] if pd.notna(row[l]) else \"\" for l in labels]\n",
    "    lines.append(f\"{row['Backbone']:<13} & \" + \" & \".join(row_vals) + r\" \\\\\")\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# 表示\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada39c00-b732-4cbd-ac88-bd7a112ef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 表示名変換 ---\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "\n",
    "# --- 出力順 ---\n",
    "backbone_order = [\"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"]\n",
    "decoder_order = [\"DRGG-BS\", \"DRGG-BEBS\"]\n",
    "\n",
    "# --- デコーダ名列の追加 ---\n",
    "decoder_map = {\n",
    "    \"DRGG\": \"DRGG-BS\",\n",
    "    \"DRGGBBoxEmbTFEnc\": \"DRGG-BEBS\"\n",
    "}\n",
    "grouped[\"Decoder\"] = grouped[\"Method\"].map(decoder_map)\n",
    "grouped[\"BackboneDisplay\"] = grouped[\"Backbone\"].map(backbone_name_map)\n",
    "\n",
    "# --- フォーマット列の生成（p < 0.05 に $^\\star$ を付ける） ---\n",
    "grouped[\"acc_str\"] = grouped.apply(\n",
    "    lambda row: f\"{row['Acc@20 (%)']:.1f} ({row['ΔAccuracy (%)']:+.1f})\"\n",
    "    + (r\"$^\\star$\" if pd.notna(row[\"p-value\"]) and row[\"p-value\"] < 0.05 else \"\"),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- ピボット ---\n",
    "df_pivot = grouped.pivot(index=[\"BackboneDisplay\", \"Decoder\"], columns=\"bin\", values=\"acc_str\").reset_index()\n",
    "\n",
    "# --- 欠損 bin 補完 ---\n",
    "for b in labels:\n",
    "    if b not in df_pivot.columns:\n",
    "        df_pivot[b] = \"\"\n",
    "df_pivot = df_pivot[[\"BackboneDisplay\", \"Decoder\"] + labels]\n",
    "\n",
    "# --- 表示順制御 ---\n",
    "df_pivot[\"BackboneDisplay\"] = pd.Categorical(df_pivot[\"BackboneDisplay\"], categories=backbone_order, ordered=True)\n",
    "df_pivot[\"Decoder\"] = pd.Categorical(df_pivot[\"Decoder\"], categories=decoder_order, ordered=True)\n",
    "df_pivot = df_pivot.sort_values([\"BackboneDisplay\", \"Decoder\"])\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{llrrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = r\"Backbone & Decoder & \" + \" & \".join(labels) + r\" \\\\\"\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for bname in backbone_order:\n",
    "    sub = df_pivot[df_pivot[\"BackboneDisplay\"] == bname]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    for i, decoder in enumerate(decoder_order):\n",
    "        row = sub[sub[\"Decoder\"] == decoder]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        vals = [row.iloc[0][l] for l in labels]\n",
    "        if i == 0:\n",
    "            # DRGG-BS 行（Backbone付き）\n",
    "            lines.append(rf\"\\multirow{{2}}{{*}}{{{bname}}} & {decoder} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "        else:\n",
    "            # DRGG-BEBS 行（Backboneなし）\n",
    "            lines.append(rf\"    & {decoder} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "    if bname != backbone_order[-1]:\n",
    "        lines.append(r\"\\midrule\")\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# --- 出力 ---\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca6c0e-b947-43ed-b722-a7adf73abcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 対象Backboneを指定して可視化（例: swin_base_384_4scale） ---\n",
    "target_backbone = \"swin_base_384_4scale\"\n",
    "target_df = grouped[grouped[\"Backbone\"] == target_backbone]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    data=target_df,\n",
    "    x=\"bin\",\n",
    "    y=\"ΔAccuracy (%)\",\n",
    "    hue=\"Method\",\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.title(f\"Accuracy Improvement by Beam Width (Reading Order) — {target_backbone}\")\n",
    "plt.xlabel(\"Normalized Distance Bin (dominant axis)\")\n",
    "plt.ylabel(\"Accuracy Improvement (%)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821c2f4-53d2-4408-941a-3c9b3ca5cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 距離 bin 定義\n",
    "bins = [0, 1, 2, 4, 8, 16, np.inf]\n",
    "labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", r\"(16, $\\infty$)\"]\n",
    "\n",
    "# 各 backbone ごとの bin × bin confusion matrix カウント\n",
    "bin_confusions_per_backbone = {backbone: defaultdict(Counter) for backbone in backbones}\n",
    "\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "# mispred割合用\n",
    "correct_counts_per_backbone = defaultdict(int)\n",
    "mispred_counts_per_backbone = defaultdict(int)\n",
    "\n",
    "def truncate_tree_at_node(root: TreeNode, stop_label: str) -> TreeNode | None:\n",
    "    \"\"\"\n",
    "    pred_tree を DFS 順に辿り、stop_label に達したらそれ以降を切り落とした部分木を返す。\n",
    "    \"\"\"\n",
    "    stopped = False  # 単なるフラグ\n",
    "\n",
    "    def dfs(node: TreeNode) -> TreeNode | None:\n",
    "        nonlocal stopped  # ← これだけでOK\n",
    "        if stopped:\n",
    "            return None\n",
    "        if node.label == stop_label:\n",
    "            stopped = True\n",
    "            return None\n",
    "\n",
    "        new_node = TreeNode(node.id, node.label, node.bbox, node.category)\n",
    "        for child in node.children:\n",
    "            if stopped:\n",
    "                break\n",
    "            child_copy = dfs(child)\n",
    "            if child_copy:\n",
    "                new_node.children.append(child_copy)\n",
    "        return new_node\n",
    "\n",
    "    return dfs(root)\n",
    "\n",
    "next_status_counts = defaultdict(lambda: [0, 0])\n",
    "\n",
    "for backbone in backbones:\n",
    "    # method = \"DRGG\"\n",
    "    method = \"DRGGBBoxEmbTFEnc\"\n",
    "    key = (backbone, method, 20)\n",
    "\n",
    "    if key not in all_preds_dict:\n",
    "        continue\n",
    "\n",
    "    preds = all_preds_dict[key]\n",
    "    for entry in preds:\n",
    "        gt = entry[\"gt_tree\"]\n",
    "        pred = entry[\"pred_tree\"]\n",
    "\n",
    "        gt_nodes = [n for n in dfs_all_nodes(gt) if n.category != -1]\n",
    "        pred_nodes = [n for n in dfs_all_nodes(pred) if n.category != -1]\n",
    "\n",
    "        pred_edges = list(zip(pred_nodes[:-1], pred_nodes[1:]))\n",
    "        pred_next_map = {n1.label: n2 for n1, n2 in pred_edges}\n",
    "\n",
    "        for i in range(len(gt_nodes) - 1):\n",
    "            n1, n2 = gt_nodes[i], gt_nodes[i + 1]\n",
    "            \n",
    "            # GT距離と bin\n",
    "            x1, y1 = bbox_center(n1.bbox)\n",
    "            x2, y2 = bbox_center(n2.bbox)\n",
    "            dx, dy = abs(x2 - x1), abs(y2 - y1)\n",
    "            if dx >= dy:\n",
    "                dist_gt = dx\n",
    "                scale = max(n1.bbox[2] - n1.bbox[0], n2.bbox[2] - n2.bbox[0])\n",
    "            else:\n",
    "                dist_gt = dy\n",
    "                scale = max(n1.bbox[3] - n1.bbox[1], n2.bbox[3] - n2.bbox[1])\n",
    "            if scale == 0:\n",
    "                continue\n",
    "            norm_dist_gt = dist_gt / scale\n",
    "            bin_gt = pd.cut([norm_dist_gt], bins=bins, labels=labels)[0]\n",
    "            if pd.isna(bin_gt):\n",
    "                continue\n",
    "        \n",
    "            # 次ノード予測\n",
    "            pred_next = pred_next_map.get(n1.label, None)\n",
    "            if pred_next is None:\n",
    "                continue\n",
    "        \n",
    "            if pred_next.label == n2.label:\n",
    "                correct_counts_per_backbone[backbone] += 1\n",
    "                continue  # 正解\n",
    "        \n",
    "            # 距離と bin\n",
    "            px, py = bbox_center(pred_next.bbox)\n",
    "            dxp, dyp = abs(px - x1), abs(py - y1)\n",
    "            if dxp >= dyp:\n",
    "                dist_pred = dxp\n",
    "                scale_p = max(n1.bbox[2] - n1.bbox[0], pred_next.bbox[2] - pred_next.bbox[0])\n",
    "            else:\n",
    "                dist_pred = dyp\n",
    "                scale_p = max(n1.bbox[3] - n1.bbox[1], pred_next.bbox[3] - pred_next.bbox[1])\n",
    "            if scale_p == 0:\n",
    "                continue\n",
    "            norm_dist_pred = dist_pred / scale_p\n",
    "            bin_pred = pd.cut([norm_dist_pred], bins=bins, labels=labels)[0]\n",
    "            if pd.isna(bin_pred):\n",
    "                continue\n",
    "        \n",
    "            # カウント：mispred\n",
    "            bin_confusions_per_backbone[backbone][bin_gt][bin_pred] += 1\n",
    "            mispred_counts_per_backbone[backbone] += 1\n",
    "\n",
    "            # 部分木構築\n",
    "            partial_tree = truncate_tree_at_node(pred, n1.label)\n",
    "            all_labels_in_tree = set(n.label for n in dfs_all_nodes(partial_tree))\n",
    "\n",
    "            if n2.label not in all_labels_in_tree:\n",
    "                next_status_counts[backbone][0] += 1  # 選択可能\n",
    "            else:\n",
    "                next_status_counts[backbone][1] += 1  # 選択不可能\n",
    "\n",
    "# 各 backbone の正規化行列を平均\n",
    "normalized_dfs = []\n",
    "for backbone, conf in bin_confusions_per_backbone.items():\n",
    "    df = pd.DataFrame.from_dict(conf, orient=\"index\", columns=labels).fillna(0).astype(int)\n",
    "    df = df.reindex(index=labels, columns=labels)\n",
    "    df_norm = df.div(df.sum(axis=1), axis=0).fillna(0)\n",
    "    normalized_dfs.append(df_norm)\n",
    "\n",
    "# 平均混同行列\n",
    "mean_distance_confusion = sum(normalized_dfs) / len(normalized_dfs)\n",
    "\n",
    "# mispred割合の出力（backboneごと + 平均）\n",
    "rates = []\n",
    "print(\"\\n=== mispredicted距離bin割合（backboneごと）===\")\n",
    "for backbone in backbones:\n",
    "    correct = correct_counts_per_backbone[backbone]\n",
    "    mispred = mispred_counts_per_backbone[backbone]\n",
    "    total = correct + mispred\n",
    "    if total > 0:\n",
    "        rate = 100 * mispred / total\n",
    "        print(f\"[{backbone}] {rate:.2f}%  ({mispred} / {total})\")\n",
    "        rates.append(rate)\n",
    "    else:\n",
    "        print(f\"[{backbone}] データなし\")\n",
    "\n",
    "if rates:\n",
    "    print(f\"\\n=== mispredicted距離bin割合（backbone平均）: {sum(rates)/len(rates):.2f}% ===\")\n",
    "else:\n",
    "    print(\"\\n=== mispredicted距離bin割合を計算できません（全backboneでデータなし） ===\")\n",
    "\n",
    "print(\"\\n=== 正解次ノードの構築時点の分類（backboneごと） ===\")\n",
    "avg_ratios = [0, 0]\n",
    "valid_backbones = 0\n",
    "for backbone, (selectable, not_selectable) in next_status_counts.items():\n",
    "    total = selectable + not_selectable\n",
    "    if total == 0:\n",
    "        continue\n",
    "    r1 = selectable / total * 100\n",
    "    r2 = not_selectable / total * 100\n",
    "    print(f\"[{backbone}]\")\n",
    "    print(f\"  1. 選択可能  : {selectable} ({r1:.2f}%)\")\n",
    "    print(f\"  2. 選択不可能: {not_selectable} ({r2:.2f}%)\")\n",
    "    avg_ratios[0] += r1\n",
    "    avg_ratios[1] += r2\n",
    "    valid_backbones += 1\n",
    "\n",
    "if valid_backbones > 0:\n",
    "    print(\"\\n=== 分類割合（backbone平均） ===\")\n",
    "    print(f\"  1. 選択可能: {avg_ratios[0]/valid_backbones:.2f}%\")\n",
    "    print(f\"  2. 選択不可能: {avg_ratios[1]/valid_backbones:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n=== データなし：backbone 平均は計算不可 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d2d20-63e7-4767-a319-c1447acfb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "ax = sns.heatmap(\n",
    "    mean_distance_confusion,  # ← GT距離bin × 予測距離bin の割合平均混同行列\n",
    "    # annot=True,\n",
    "    # fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.xlabel(\"Distance of Mispredicted BBox\", fontsize=18)\n",
    "plt.ylabel(\"Distance of GT BBox\", fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=18)\n",
    "plt.yticks(rotation=0, fontsize=18)\n",
    "# plt.title(\"Average Confusion Matrix of Normalized Reading Distances (beam20)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/reading_order_error_distance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"./figures/reading_order_error_distance.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8f119-b254-4728-ba8d-298eaa81a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- 親子関係抽出 -----\n",
    "def get_edges(node, skip_root=True):\n",
    "    edges = []\n",
    "    for child in node.children:\n",
    "        if not (skip_root and node.category == -1):\n",
    "            edges.append((node.label, child.label))\n",
    "        edges.extend(get_edges(child, skip_root))\n",
    "    return edges\n",
    "\n",
    "# ----- Node ID → Node 対応辞書 -----\n",
    "def build_node_dict(node):\n",
    "    nodes = {}\n",
    "    def recurse(n):\n",
    "        nodes[n.label] = n\n",
    "        for c in n.children:\n",
    "            recurse(c)\n",
    "    recurse(node)\n",
    "    return nodes\n",
    "\n",
    "# ----- 方向判定 -----\n",
    "def edge_direction(parent, child):\n",
    "    x1, y1 = bbox_center(parent.bbox)\n",
    "    x2, y2 = bbox_center(child.bbox)\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    if dx < 0 and dy < 0:\n",
    "        return \"左上\"\n",
    "    elif dx > 0 and dy < 0:\n",
    "        return \"右上\"\n",
    "    elif dx < 0 and dy > 0:\n",
    "        return \"左下\"\n",
    "    elif dx >= 0 and dy >= 0:\n",
    "        return \"右下\"\n",
    "    else:\n",
    "        return \"その他\"\n",
    "\n",
    "# ----- 設定 -----\n",
    "methods = [(\"DRGG\", \"DRGGBBoxEmbTFEnc\")]\n",
    "beam_widths = [1, 20]\n",
    "directions = [\"左上\", \"右上\", \"左下\", \"右下\"]\n",
    "\n",
    "records = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method_A, method_B in methods:\n",
    "        for beam_width in beam_widths:\n",
    "            key_A = (backbone, method_A, beam_width)\n",
    "            key_B = (backbone, method_B, beam_width)\n",
    "\n",
    "            if key_A not in all_preds_dict or key_B not in all_preds_dict:\n",
    "                print(f\"[WARN] Missing: {key_A} or {key_B}\")\n",
    "                continue\n",
    "\n",
    "            preds_A = all_preds_dict[key_A]\n",
    "            preds_B = all_preds_dict[key_B]\n",
    "\n",
    "            map_A = {p[\"file_name\"]: p for p in preds_A}\n",
    "            map_B = {p[\"file_name\"]: p for p in preds_B}\n",
    "\n",
    "            for fname in sorted(set(map_A) & set(map_B)):\n",
    "                gt = map_A[fname][\"gt_tree\"]\n",
    "                pred_A = map_A[fname][\"pred_tree\"]\n",
    "                pred_B = map_B[fname][\"pred_tree\"]\n",
    "\n",
    "                gt_edges = get_edges(gt, skip_root=True)\n",
    "                pred_edges_A = set(get_edges(pred_A, skip_root=True))\n",
    "                pred_edges_B = set(get_edges(pred_B, skip_root=True))\n",
    "                if len(gt_edges) == 0:\n",
    "                    continue\n",
    "\n",
    "                correct_A = sum(e in pred_edges_A for e in gt_edges)\n",
    "                correct_B = sum(e in pred_edges_B for e in gt_edges)\n",
    "                acc_A = correct_A / len(gt_edges)\n",
    "                acc_B = correct_B / len(gt_edges)\n",
    "                acc_diff = acc_B - acc_A\n",
    "\n",
    "                node_dict = build_node_dict(gt)\n",
    "                dir_count = Counter()\n",
    "                for pid, cid in gt_edges:\n",
    "                    p, c = node_dict[pid], node_dict[cid]\n",
    "                    d = edge_direction(p, c)\n",
    "                    if d in directions:\n",
    "                        dir_count[d] += 1\n",
    "\n",
    "                records.append({\n",
    "                    \"Backbone\": backbone,\n",
    "                    \"Method A\": method_A,\n",
    "                    \"Method B\": method_B,\n",
    "                    \"Beam Width\": beam_width,\n",
    "                    \"file_name\": fname,\n",
    "                    \"accuracy_diff\": acc_diff,\n",
    "                    **dir_count\n",
    "                })\n",
    "\n",
    "# ----- DataFrame 化と相関 -----\n",
    "df = pd.DataFrame(records).fillna(0)\n",
    "\n",
    "results = []\n",
    "for d in directions:\n",
    "    for (backbone, method_A, method_B, beam_width), grp in df.groupby([\"Backbone\", \"Method A\", \"Method B\", \"Beam Width\"]):\n",
    "        if grp[d].sum() == 0:\n",
    "            continue\n",
    "        r, p = pearsonr(grp[d], grp[\"accuracy_diff\"])\n",
    "        results.append({\n",
    "            \"Backbone\": backbone,\n",
    "            \"Method A\": method_A,\n",
    "            \"Method B\": method_B,\n",
    "            \"Beam Width\": beam_width,\n",
    "            \"Direction\": d,\n",
    "            \"Pearson r\": r,\n",
    "            \"p-value\": p\n",
    "        })\n",
    "\n",
    "df_corr = pd.DataFrame(results)\n",
    "\n",
    "# --- 相関値を \"r†\" 形式に整形 ---\n",
    "def format_r_dagger(row):\n",
    "    r_val = f\"{row['Pearson r']:.3f}\"\n",
    "    return f\"{r_val}$\\\\dagger$\" if row[\"p-value\"] < 0.001 else r_val\n",
    "\n",
    "df_corr[\"r(p)\"] = df_corr.apply(format_r_dagger, axis=1)\n",
    "\n",
    "# --- ピボット & 整形 ---\n",
    "df_pivot = df_corr.pivot(index=[\"Backbone\", \"Method A\", \"Method B\", \"Beam Width\"], columns=\"Direction\", values=\"r(p)\").reset_index()\n",
    "df_pivot[\"Method A → B\"] = df_pivot[\"Method A\"] + \" → \" + df_pivot[\"Method B\"]\n",
    "df_pivot = df_pivot[[\"Backbone\", \"Method A → B\"] + directions]\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    caption=r\"Correlation between parent-child direction counts and accuracy improvement (Method B − Method A). Pearson $r$ shown; $p < 0.001$ marked with $\\dagger$.\",\n",
    "    label=\"tab:parent_child_direction_compact\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== 整形済み相関表 ===\")\n",
    "print(df_pivot.to_string(index=False))\n",
    "print(\"\\n=== LaTeX 出力 ===\")\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81521f75-601a-42a5-b35c-e4fee17b9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from math import atan2, degrees\n",
    "\n",
    "# --- bbox 中心（xyxy形式） ---\n",
    "def bbox_center(bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    return (x_min + x_max) / 2, (y_min + y_max) / 2\n",
    "\n",
    "# --- 8方向分類（45度刻み） ---\n",
    "def classify_8_directions(dx, dy):\n",
    "    angle = (degrees(atan2(dy, dx)) + 360) % 360\n",
    "    if (337.5 <= angle < 360) or (0 <= angle < 22.5):\n",
    "        return \"右\"\n",
    "    elif 22.5 <= angle < 67.5:\n",
    "        return \"右下\"\n",
    "    elif 67.5 <= angle < 112.5:\n",
    "        return \"下\"\n",
    "    elif 112.5 <= angle < 157.5:\n",
    "        return \"左下\"\n",
    "    elif 157.5 <= angle < 202.5:\n",
    "        return \"左\"\n",
    "    elif 202.5 <= angle < 247.5:\n",
    "        return \"左上\"\n",
    "    elif 247.5 <= angle < 292.5:\n",
    "        return \"上\"\n",
    "    elif 292.5 <= angle < 337.5:\n",
    "        return \"右上\"\n",
    "    else:\n",
    "        return \"不明\"\n",
    "\n",
    "direction_types = [\"右\", \"右下\", \"下\", \"左下\", \"左\", \"左上\", \"上\", \"右上\", \"Root\"]\n",
    "records = []\n",
    "\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "for backbone in backbones:\n",
    "    for method_A, method_B in [(\"DRGG\", \"DRGGBBoxEmbTFEnc\")]:\n",
    "        for beam_width in [1, 20]:\n",
    "            key_A = (backbone, method_A, beam_width)\n",
    "            key_B = (backbone, method_B, beam_width)\n",
    "\n",
    "            if key_A not in all_preds_dict or key_B not in all_preds_dict:\n",
    "                print(f\"[WARN] Missing: {key_A} or {key_B}\")\n",
    "                continue\n",
    "\n",
    "            preds_A = all_preds_dict[key_A]\n",
    "            preds_B = all_preds_dict[key_B]\n",
    "            map_A = {p[\"file_name\"]: p for p in preds_A}\n",
    "            map_B = {p[\"file_name\"]: p for p in preds_B}\n",
    "            common_files = set(map_A) & set(map_B)\n",
    "\n",
    "            # --- カウント初期化 ---\n",
    "            stats = {d: {\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0} for d in direction_types}\n",
    "\n",
    "            for fname in common_files:\n",
    "                gt = map_A[fname][\"gt_tree\"]\n",
    "                pred_A = map_A[fname][\"pred_tree\"]\n",
    "                pred_B = map_B[fname][\"pred_tree\"]\n",
    "\n",
    "                gt_edges = get_edges(gt, skip_root=False)  # ✅ Root を含む\n",
    "                pred_edges_A = set(get_edges(pred_A, skip_root=False))\n",
    "                pred_edges_B = set(get_edges(pred_B, skip_root=False))\n",
    "                node_dict = build_node_dict(gt)\n",
    "\n",
    "                for pid, cid in gt_edges:\n",
    "                    if pid not in node_dict or cid not in node_dict:\n",
    "                        continue\n",
    "                    p_node = node_dict[pid]\n",
    "                    c_node = node_dict[cid]\n",
    "                \n",
    "                    if p_node.category == -1:\n",
    "                        direction = \"Root\"\n",
    "                    else:\n",
    "                        x1, y1 = bbox_center(p_node.bbox)\n",
    "                        x2, y2 = bbox_center(c_node.bbox)\n",
    "                        dx, dy = x2 - x1, y2 - y1\n",
    "                        direction = classify_8_directions(dx, dy)\n",
    "                \n",
    "                    if direction not in direction_types:\n",
    "                        continue\n",
    "                \n",
    "                    edge = (pid, cid)\n",
    "                    correct_A = edge in pred_edges_A\n",
    "                    correct_B = edge in pred_edges_B\n",
    "                \n",
    "                    if correct_A and correct_B:\n",
    "                        stats[direction][\"A\"] += 1\n",
    "                    elif correct_A and not correct_B:\n",
    "                        stats[direction][\"B\"] += 1\n",
    "                    elif not correct_A and correct_B:\n",
    "                        stats[direction][\"C\"] += 1\n",
    "                    else:\n",
    "                        stats[direction][\"D\"] += 1\n",
    "\n",
    "\n",
    "            row = {\n",
    "                \"Backbone\": backbone,\n",
    "                \"Method A → B\": f\"{method_A} → {method_B}\",\n",
    "                \"Beam Width\": beam_width\n",
    "            }\n",
    "            for d in direction_types:\n",
    "                A = stats[d][\"A\"]\n",
    "                B = stats[d][\"B\"]\n",
    "                C = stats[d][\"C\"]\n",
    "                D = stats[d][\"D\"]\n",
    "                total = A + B + C + D\n",
    "            \n",
    "                if total == 0:\n",
    "                    row[d] = \"\"\n",
    "                else:\n",
    "                    acc_A = (A + B) / total * 100\n",
    "                    acc_B = (A + C) / total * 100\n",
    "                    delta = acc_B - acc_A\n",
    "            \n",
    "                    try:\n",
    "                        if B + C >= 5:\n",
    "                            result = mcnemar([[A, B], [C, D]], exact=True)\n",
    "                            p = result.pvalue\n",
    "                        else:\n",
    "                            p = None\n",
    "                    except Exception as e:\n",
    "                        print(f\"[WARN] McNemar failed: {backbone}, {method_A}→{method_B}, {d}: {e}\")\n",
    "                        p = None\n",
    "            \n",
    "                    acc_str = (\n",
    "                        f\"\\\\textbf{{{acc_B:.1f}}} ({delta:+.1f})\"\n",
    "                        if p is not None and p < 0.05\n",
    "                        else f\"{acc_B:.1f} ({delta:+.1f})\"\n",
    "                    )\n",
    "                    row[d] = acc_str\n",
    "            records.append(row)\n",
    "\n",
    "# --- DataFrame 化 & 表示 ---\n",
    "df = pd.DataFrame(records)\n",
    "df = df[[\"Backbone\", \"Method A → B\", \"Beam Width\"] + direction_types]\n",
    "\n",
    "# print(\"\\n=== GTエッジの方向別 accuracy@20 (+Δ) ===\")\n",
    "# print(df.to_string(index=False))\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"lll\" + \"c\" * len(direction_types),\n",
    "    caption=r\"Accuracy@20 per GT parent-child edge direction (8 directions), with improvement from Method A. Format: acc20 (+Δ).\",\n",
    "    label=\"tab:gt_edge_direction_accuracy\"\n",
    ")\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272430a-1f13-4c7c-ac1d-2d34472bf96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_directional_significance(df: pd.DataFrame, direction_types):\n",
    "    print(\"\\n=== 方向別有意差 (p < 0.05, McNemar) ===\")\n",
    "    for _, row in df.iterrows():\n",
    "        heading = f\"[Backbone={row['Backbone']} | Method={row['Method A → B']} | Beam Width={row['Beam Width']}]\"\n",
    "        print(heading)\n",
    "        line = \"  \"\n",
    "        for d in direction_types:\n",
    "            val = row[d]\n",
    "            if isinstance(val, str) and val.startswith(\"\\\\textbf{\"):\n",
    "                mark = \"✔\"\n",
    "            elif isinstance(val, str) and val != \"\":\n",
    "                mark = \"✘\"\n",
    "            else:\n",
    "                mark = \"－\"\n",
    "            line += f\"{mark} {d:<6} \"\n",
    "        print(line)\n",
    "\n",
    "print_directional_significance(df, direction_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398fff0-ba26-4061-805b-b0136dbc9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Backbone 表示名マップ ---\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "\n",
    "# --- 表示順の方向英語ラベル（Root除外） ---\n",
    "direction_display = {\n",
    "    \"右\": \"Right\",\n",
    "    \"右下\": \"Bottom-Right\",\n",
    "    \"下\": \"Bottom\",\n",
    "    \"左下\": \"Bottom-Left\",\n",
    "    \"左\": \"Left\",\n",
    "    \"左上\": \"Top-Left\",\n",
    "    \"上\": \"Top\",\n",
    "    \"右上\": \"Top-Right\",\n",
    "}\n",
    "ordered_dirs = list(direction_display.keys())\n",
    "\n",
    "# textbf を $^\\star$ に変換\n",
    "def convert_textbf_to_star(cell):\n",
    "    if not isinstance(cell, str):\n",
    "        return cell\n",
    "    m = re.match(r\"\\\\textbf{([\\d.]+)} \\(([-+.\\d]+)\\)\", cell)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} ({m.group(2)})$^\\\\star$\"\n",
    "    return re.sub(r\"\\\\textbf{([^}]*)}\", r\"\\1\", cell).strip()\n",
    "\n",
    "# --- DRGG-BEBS のみ抽出 ---\n",
    "df_bebs = df[\n",
    "    (df[\"Method A → B\"] == \"DRGG → DRGGBBoxEmbTFEnc\") &\n",
    "    (df[\"Beam Width\"] == 20)\n",
    "].copy()\n",
    "df_bebs[\"BackboneName\"] = df_bebs[\"Backbone\"].map(backbone_name_map)\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{l|rrrrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = (\n",
    "    r\"\\multicolumn{1}{l}{Backbone} & \" +\n",
    "    \" & \".join([rf\"\\multicolumn{{1}}{{l}}{{{direction_display[d]}}}\" for d in ordered_dirs]) +\n",
    "    r\" \\\\\"\n",
    ")\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for b in [\"ResNet-50\", \"ViT\", \"Swin\", \"DiT\", \"InternImage\"]:\n",
    "    row = df_bebs[df_bebs[\"BackboneName\"] == b]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    vals = [convert_textbf_to_star(row.iloc[0][d]) if d in row.columns else \"\" for d in ordered_dirs]\n",
    "    lines.append(f\"{b:<15} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# --- 出力 ---\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e6f7d-01e6-474e-8817-d98a730e61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "\n",
    "# 表示マップ\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "direction_display = {\n",
    "    \"右\": \"Right\", \"右下\": \"Bottom-Right\", \"下\": \"Bottom\",\n",
    "    \"左下\": \"Bottom-Left\", \"左\": \"Left\", \"左上\": \"Top-Left\",\n",
    "    \"上\": \"Top\", \"右上\": \"Top-Right\"\n",
    "}\n",
    "ordered_dirs = list(direction_display.keys())\n",
    "backbone_order = list(backbone_name_map.values())\n",
    "decoder_map = {1: \"DRGG-BE\", 20: \"DRGG-BEBS\"}\n",
    "\n",
    "# textbf を $^\\star$ に変換\n",
    "def convert_textbf_to_star(cell):\n",
    "    if not isinstance(cell, str): return cell\n",
    "    m = re.match(r\"\\\\textbf{([\\d.]+)} \\(([-+.\\d]+)\\)\", cell)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} ({m.group(2)})$^\\\\star$\"\n",
    "    return re.sub(r\"\\\\textbf{([^}]*)}\", r\"\\1\", cell).strip()\n",
    "\n",
    "# 前処理\n",
    "df[\"BackboneDisplay\"] = df[\"Backbone\"].map(backbone_name_map)\n",
    "for d in ordered_dirs:\n",
    "    if d in df.columns:\n",
    "        df[d] = df[d].apply(convert_textbf_to_star)\n",
    "\n",
    "# レコード構築\n",
    "records = []\n",
    "for backbone in backbone_order:\n",
    "    for beam_width in [1, 20]:\n",
    "        decoder = decoder_map[beam_width]\n",
    "        row = df[\n",
    "            (df[\"BackboneDisplay\"] == backbone) &\n",
    "            (df[\"Method A → B\"] == \"DRGG → DRGGBBoxEmbTFEnc\") &\n",
    "            (df[\"Beam Width\"] == beam_width)\n",
    "        ]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        rec = {\"Backbone\": backbone, \"Decoder\": decoder}\n",
    "        for d in ordered_dirs:\n",
    "            rec[d] = row.iloc[0][d]\n",
    "        records.append(rec)\n",
    "\n",
    "# LaTeX 出力\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{ll|rrrrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = (\n",
    "    r\"\\multicolumn{1}{l}{Backbone} & \\multicolumn{1}{l}{Decoder} & \" +\n",
    "    \" & \".join([rf\"\\multicolumn{{1}}{{l}}{{{direction_display[d]}}}\" for d in ordered_dirs]) +\n",
    "    r\" \\\\\"\n",
    ")\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for backbone, group in groupby(records, key=lambda r: r[\"Backbone\"]):\n",
    "    group = list(group)\n",
    "    for i, row in enumerate(group):\n",
    "        vals = [row[d] for d in ordered_dirs]\n",
    "        if i == 0:\n",
    "            lines.append(rf\"\\multirow{{2}}{{*}}{{{backbone}}} & {row['Decoder']} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "        else:\n",
    "            lines.append(rf\"    & {row['Decoder']} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "    if backbone != backbone_order[-1]:\n",
    "        lines.append(r\"\\midrule\")\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# 出力\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16da17-c090-483c-aed5-c75bc0f69491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方向タイプ（Rootを含む）\n",
    "direction_types = [\"右\", \"右下\", \"下\", \"左下\", \"左\", \"左上\", \"上\", \"右上\", \"Root\"]\n",
    "\n",
    "# 日本語→英語対応（Root含む）\n",
    "jp_to_en = {\n",
    "    \"右\": \"Right\",\n",
    "    \"右下\": \"Bottom-Right\",\n",
    "    \"下\": \"Bottom\",\n",
    "    \"左下\": \"Bottom-Left\",\n",
    "    \"左\": \"Left\",\n",
    "    \"左上\": \"Top-Left\",\n",
    "    \"上\": \"Top\",\n",
    "    \"右上\": \"Top-Right\",\n",
    "    \"Root\": \"Root\"\n",
    "}\n",
    "direction_types_en = [jp_to_en[d] for d in direction_types]\n",
    "\n",
    "# --- backbone ごとの混同行列カウント ---\n",
    "confusions_per_backbone = {b: defaultdict(Counter) for b in backbones}\n",
    "\n",
    "method = \"DRGGBBoxEmbTFEnc\"\n",
    "beam_width = 20\n",
    "\n",
    "def truncate_tree_at_node(root: TreeNode, stop_label: str) -> TreeNode | None:\n",
    "    \"\"\"\n",
    "    pred_tree を DFS 順に辿り、stop_label に達したらそれ以降を切り落とした部分木を返す。\n",
    "    \"\"\"\n",
    "    stopped = False  # 単なるフラグ\n",
    "\n",
    "    def dfs(node: TreeNode) -> TreeNode | None:\n",
    "        nonlocal stopped  # ← これだけでOK\n",
    "        if stopped:\n",
    "            return None\n",
    "        if node.label == stop_label:\n",
    "            stopped = True\n",
    "            return None\n",
    "\n",
    "        new_node = TreeNode(node.id, node.label, node.bbox, node.category)\n",
    "        for child in node.children:\n",
    "            if stopped:\n",
    "                break\n",
    "            child_copy = dfs(child)\n",
    "            if child_copy:\n",
    "                new_node.children.append(child_copy)\n",
    "        return new_node\n",
    "\n",
    "    return dfs(root)\n",
    "\n",
    "def get_rightmost_path(root):\n",
    "    path = []\n",
    "    node = root\n",
    "    while node and node.children:\n",
    "        path.append(node.id)\n",
    "        node = node.children[-1]\n",
    "    if node:\n",
    "        path.append(node.id)\n",
    "    return path\n",
    "\n",
    "correct_counts_per_backbone = defaultdict(int)\n",
    "mispred_counts_per_backbone = defaultdict(int)\n",
    "parent_status_counts = defaultdict(lambda: [0, 0, 0])\n",
    "\n",
    "for backbone in backbones:\n",
    "    key = (backbone, method, beam_width)\n",
    "    if key not in all_preds_dict:\n",
    "        print(f\"[WARN] Missing: {key}\")\n",
    "        continue\n",
    "\n",
    "    preds = all_preds_dict[key]\n",
    "    for entry in preds:\n",
    "        gt = entry[\"gt_tree\"]\n",
    "        pred = entry[\"pred_tree\"]\n",
    "\n",
    "        gt_edges = get_edges(gt, skip_root=False)\n",
    "        pred_edges = get_edges(pred, skip_root=False)\n",
    "        gt_nodes = build_node_dict(gt)\n",
    "        pred_nodes = build_node_dict(pred)\n",
    "\n",
    "        pred_edge_dirs = {}\n",
    "        for pid, cid in pred_edges:\n",
    "            if pid in pred_nodes and cid in pred_nodes:\n",
    "                if pred_nodes[pid].category == -1 or pred_nodes[cid].category == -1:\n",
    "                    dir_ = \"Root\"\n",
    "                else:\n",
    "                    x1, y1 = bbox_center(pred_nodes[pid].bbox)\n",
    "                    x2, y2 = bbox_center(pred_nodes[cid].bbox)\n",
    "                    dir_ = classify_8_directions(x2 - x1, y2 - y1)\n",
    "                pred_edge_dirs[(pid, cid)] = dir_\n",
    "\n",
    "        for pid, cid in gt_edges:\n",
    "            if pid not in gt_nodes or cid not in gt_nodes:\n",
    "                continue\n",
    "\n",
    "            if gt_nodes[pid].category == -1 or gt_nodes[cid].category == -1:\n",
    "                gt_dir = \"Root\"\n",
    "            else:\n",
    "                x1, y1 = bbox_center(gt_nodes[pid].bbox)\n",
    "                x2, y2 = bbox_center(gt_nodes[cid].bbox)\n",
    "                gt_dir = classify_8_directions(x2 - x1, y2 - y1)\n",
    "\n",
    "            if gt_dir not in direction_types:\n",
    "                continue\n",
    "\n",
    "            # 正解ならスキップ\n",
    "            if (pid, cid) in pred_edge_dirs:\n",
    "                correct_counts_per_backbone[backbone] += 1\n",
    "                continue\n",
    "\n",
    "            # 子ノード cid に対する予測方向\n",
    "            pred_dir = None\n",
    "            for (ppid, ccid), d in pred_edge_dirs.items():\n",
    "                if ccid == cid:\n",
    "                    pred_dir = d\n",
    "                    break\n",
    "\n",
    "            if pred_dir not in direction_types:\n",
    "                continue\n",
    "\n",
    "            confusions_per_backbone[backbone][gt_dir][pred_dir] += 1\n",
    "            mispred_counts_per_backbone[backbone] += 1\n",
    "\n",
    "            # 部分木構築\n",
    "            partial_tree = truncate_tree_at_node(pred, pred_nodes[cid].label)\n",
    "            if not partial_tree:\n",
    "                parent_status_counts[backbone][2] += 1\n",
    "                continue\n",
    "        \n",
    "            rightmost_path = set(get_rightmost_path(partial_tree))\n",
    "            all_labels_in_tree = set(n.label for n in dfs_all_nodes(partial_tree))\n",
    "                \n",
    "            if gt_nodes[pid].label in rightmost_path:\n",
    "                parent_status_counts[backbone][0] += 1  # right frontier にいた\n",
    "            elif gt_nodes[pid].label in all_labels_in_tree:\n",
    "                parent_status_counts[backbone][1] += 1  # 構築済みにいたが frontier にいなかった\n",
    "            else:\n",
    "                parent_status_counts[backbone][2] += 1  # まだ構築されていない（読み順の矛盾）\n",
    "\n",
    "normalized_dfs = []\n",
    "for backbone, confusion in confusions_per_backbone.items():\n",
    "    df = pd.DataFrame.from_dict(confusion, orient=\"index\", columns=direction_types).fillna(0).astype(int)\n",
    "    df = df.reindex(index=direction_types, columns=direction_types).fillna(0).astype(int)\n",
    "    df_norm = df.div(df.sum(axis=1), axis=0).fillna(0)\n",
    "    df_norm.index = [jp_to_en[d] for d in df_norm.index]\n",
    "    df_norm.columns = [jp_to_en[d] for d in df_norm.columns]\n",
    "    normalized_dfs.append(df_norm)\n",
    "\n",
    "mean_confusion = sum(normalized_dfs) / len(normalized_dfs)\n",
    "\n",
    "print(\"\\n=== mispredicted方向割合（backboneごと）===\")\n",
    "mispred_rates = []\n",
    "for backbone in backbones:\n",
    "    correct = correct_counts_per_backbone[backbone]\n",
    "    mispred = mispred_counts_per_backbone[backbone]\n",
    "    total = correct + mispred\n",
    "    if total > 0:\n",
    "        rate = 100 * mispred / total\n",
    "        print(f\"[{backbone}] {rate:.2f}%  ({mispred} / {total})\")\n",
    "        mispred_rates.append(rate)\n",
    "    else:\n",
    "        print(f\"[{backbone}] データなし\")\n",
    "\n",
    "if mispred_rates:\n",
    "    print(f\"\\n=== mispredicted方向割合（backbone平均）: {sum(mispred_rates)/len(mispred_rates):.2f}% ===\")\n",
    "else:\n",
    "    print(\"\\n=== mispredicted方向割合を計算できません（全backboneでデータなし） ===\")\n",
    "\n",
    "print(\"\\n=== 正解親の構築時点の分類（backboneごと） ===\")\n",
    "avg_ratios = [0, 0, 0]  # [in_frontier, in_tree, not_built]\n",
    "valid_backbones = 0\n",
    "for backbone, (in_frontier, in_tree, not_built) in parent_status_counts.items():\n",
    "    total = in_frontier + in_tree + not_built\n",
    "    if total == 0:\n",
    "        continue\n",
    "    r1 = in_frontier / total * 100\n",
    "    r2 = in_tree / total * 100\n",
    "    r3 = not_built / total * 100\n",
    "    print(f\"[{backbone}]\")\n",
    "    print(f\"  1. rightmost path に存在       : {in_frontier} ({r1:.2f}%)\")\n",
    "    print(f\"  2. rightmost path 以外の木に存在: {in_tree} ({r2:.2f}%)\")\n",
    "    print(f\"  3. 正解の親が子より後ろの読み順  : {not_built} ({r3:.2f}%)\")\n",
    "    avg_ratios[0] += r1\n",
    "    avg_ratios[1] += r2\n",
    "    avg_ratios[2] += r3\n",
    "    valid_backbones += 1\n",
    "\n",
    "if valid_backbones > 0:\n",
    "    print(\"\\n=== 分類割合（backbone平均） ===\")\n",
    "    print(f\"  1. rightmost path に存在       : {avg_ratios[0]/valid_backbones:.2f}%\")\n",
    "    print(f\"  2. rightmost path 以外の木に存在: {avg_ratios[1]/valid_backbones:.2f}%\")\n",
    "    print(f\"  3. 正解の親が子より後ろの読み順  : {avg_ratios[2]/valid_backbones:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n=== データなし：backbone 平均は計算不可 ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8997cf-7f44-4f0e-abf1-600006baa516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.heatmap(\n",
    "    mean_confusion,\n",
    "    # annot=True,\n",
    "    # fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=direction_types_en,\n",
    "    yticklabels=direction_types_en\n",
    ")\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.xlabel(\"Direction of Mispredicted BBox\", fontsize=18)\n",
    "plt.ylabel(\"Direction of GT BBox\", fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/parent_child_error_direction.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"./figures/parent_child_error_direction.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56faf1a2-fd45-44c2-8b9e-ada82bb4cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method_A, method_B in [(\"DRGG\", \"DRGGBBoxEmbTFEnc\")]:\n",
    "        for beam_width in [1, 20]:\n",
    "            key_A = (backbone, method_A, beam_width)\n",
    "            key_B = (backbone, method_B, beam_width)\n",
    "\n",
    "            if key_A not in all_preds_dict or key_B not in all_preds_dict:\n",
    "                continue\n",
    "\n",
    "            preds_A = all_preds_dict[key_A]\n",
    "            preds_B = all_preds_dict[key_B]\n",
    "\n",
    "            map_A = {p[\"file_name\"]: p for p in preds_A}\n",
    "            map_B = {p[\"file_name\"]: p for p in preds_B}\n",
    "            common_files = set(map_A) & set(map_B)\n",
    "\n",
    "            for fname in common_files:\n",
    "                seen = set()\n",
    "                gt = map_A[fname][\"gt_tree\"]\n",
    "                pred_A = map_A[fname][\"pred_tree\"]\n",
    "                pred_B = map_B[fname][\"pred_tree\"]\n",
    "\n",
    "                node_dict = build_node_dict(gt)\n",
    "                gt_edges = get_edges(gt, skip_root=False)  # ✅ Root含む\n",
    "                pred_edges_A = set((e[0], e[1]) for e in get_edges(pred_A, skip_root=False))\n",
    "                pred_edges_B = set((e[0], e[1]) for e in get_edges(pred_B, skip_root=False))\n",
    "\n",
    "                for pid, cid in gt_edges:\n",
    "                    edge_id = (fname, pid, cid)\n",
    "                    if edge_id in seen:\n",
    "                        continue\n",
    "                    seen.add(edge_id)\n",
    "\n",
    "                    if pid not in node_dict or cid not in node_dict:\n",
    "                        continue\n",
    "\n",
    "                    parent = node_dict[pid]\n",
    "                    child = node_dict[cid]\n",
    "\n",
    "                    # --- Rootカテゴリの特殊扱い ---\n",
    "                    if parent.category == -1 or child.category == -1:\n",
    "                        bin_label = \"Root\"\n",
    "                    else:\n",
    "                        x1, y1 = bbox_center(parent.bbox)\n",
    "                        x2, y2 = bbox_center(child.bbox)\n",
    "                        dx = abs(x2 - x1)\n",
    "                        dy = abs(y2 - y1)\n",
    "\n",
    "                        if dx >= dy:\n",
    "                            scale = max(parent.bbox[2] - parent.bbox[0], child.bbox[2] - child.bbox[0])\n",
    "                            dist = dx\n",
    "                        else:\n",
    "                            scale = max(parent.bbox[3] - parent.bbox[1], child.bbox[3] - child.bbox[1])\n",
    "                            dist = dy\n",
    "\n",
    "                        if scale <= 0:\n",
    "                            continue  # 無効スケールはスキップ\n",
    "\n",
    "                        norm_dist = dist / scale\n",
    "                        bin_label = norm_dist\n",
    "\n",
    "                    correct_A = int((pid, cid) in pred_edges_A)\n",
    "                    correct_B = int((pid, cid) in pred_edges_B)\n",
    "\n",
    "                    records.append({\n",
    "                        \"Backbone\": backbone,\n",
    "                        \"Method A → B\": f\"{method_A} → {method_B}\",\n",
    "                        \"Beam Width\": beam_width,\n",
    "                        \"file\": fname,\n",
    "                        \"distance\": bin_label,  # 数値 or \"Root\"\n",
    "                        \"Acc A\": correct_A,\n",
    "                        \"Acc B\": correct_B,\n",
    "                        \"Diff\": correct_B - correct_A\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10906850-617f-4c00-9142-bd880024c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- DataFrame 化 ---\n",
    "df_dist = pd.DataFrame(records)\n",
    "\n",
    "# --- ビン定義 ---\n",
    "bins = [0, 1, 2, 4, 8, 16, np.inf]\n",
    "labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", \"(16, \\infty)\", \"Root\"]\n",
    "\n",
    "# --- bin 割り当て ---\n",
    "df_dist[\"bin\"] = None\n",
    "mask_numeric = df_dist[\"distance\"] != \"Root\"\n",
    "df_dist.loc[mask_numeric, \"bin\"] = pd.cut(df_dist.loc[mask_numeric, \"distance\"], bins=bins, labels=labels[:-1])\n",
    "df_dist.loc[~mask_numeric, \"bin\"] = \"Root\"\n",
    "\n",
    "# --- 集計 ---\n",
    "grouped = df_dist.groupby([\"Backbone\", \"Method A → B\", \"Beam Width\", \"bin\"]).agg(\n",
    "    Count=(\"Diff\", \"count\"),\n",
    "    Acc_A=(\"Acc A\", \"mean\"),\n",
    "    Acc_B=(\"Acc B\", \"mean\"),\n",
    "    Diff=(\"Diff\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# --- パーセント表示列 ---\n",
    "grouped[\"Acc A (%)\"] = (grouped[\"Acc_A\"] * 100).round(2)\n",
    "grouped[\"Acc B (%)\"] = (grouped[\"Acc_B\"] * 100).round(2)\n",
    "grouped[\"Diff (%)\"] = (grouped[\"Diff\"] * 100).round(2)\n",
    "\n",
    "# --- 出力 ---\n",
    "# print(grouped.to_string(index=False))\n",
    "\n",
    "# --- 可視化（Backboneごと、Root含む） ---\n",
    "target_df = grouped[grouped[\"Backbone\"] == \"vitdet_base_4scale\"]\n",
    "target_df[\"bin\"] = pd.Categorical(target_df[\"bin\"], categories=labels, ordered=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=target_df, x=\"bin\", y=\"Diff (%)\", hue=\"Beam Width\")\n",
    "plt.title(\"Accuracy Improvement per Distance Bin (vitdet_base_4scale)\")\n",
    "plt.xlabel(\"Normalized Distance Bin\")\n",
    "plt.ylabel(\"Accuracy Improvement (%)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35232258-8288-4b13-8360-809a4259aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- \"acc20 (+Δ)\" 形式に整形 ---\n",
    "grouped[\"acc_str\"] = grouped.apply(\n",
    "    lambda row: f\"{row['Acc B (%)']:.1f} ({row['Diff (%)']:+.1f})\", axis=1\n",
    ")\n",
    "\n",
    "# --- ピボット: 距離binを列に展開 ---\n",
    "bin_labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", \"(16, \\infty)\", \"Root\"]\n",
    "df_pivot = grouped.pivot(\n",
    "    index=[\"Backbone\", \"Method A → B\", \"Beam Width\"],\n",
    "    columns=\"bin\",\n",
    "    values=\"acc_str\"\n",
    ").reset_index()\n",
    "\n",
    "# --- 列順明示 ---\n",
    "for b in bin_labels:\n",
    "    if b not in df_pivot.columns:\n",
    "        df_pivot[b] = \"\"\n",
    "df_pivot = df_pivot[[\"Backbone\", \"Method A → B\", \"Beam Width\"] + bin_labels]\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"lll\" + \"c\" * len(bin_labels),\n",
    "    caption=r\"Accuracy@20 per parent-child vertical distance bin, with improvement from Method A. Format: acc20 (+Δ).\",\n",
    "    label=\"tab:distance_bin_accuracy\"\n",
    ")\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa5e5e-4bf9-4d04-88ca-85afb7041e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# --- ビン化（数値 + Root） ---\n",
    "bins = [0, 1, 2, 4, 8, 16, np.inf]\n",
    "labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", \"(16, ∞)\"]\n",
    "\n",
    "def assign_bin(val):\n",
    "    if val == \"Root\":\n",
    "        return \"Root\"\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] < val <= bins[i + 1]:\n",
    "            return labels[i]\n",
    "    return None\n",
    "\n",
    "df[\"bin\"] = df[\"distance\"].apply(assign_bin)\n",
    "df = df.dropna(subset=[\"bin\"])\n",
    "\n",
    "# --- McNemar検定と集計 ---\n",
    "agg_records = []\n",
    "\n",
    "for (backbone, method_pair, beam_width, bin_label), g in df.groupby([\"Backbone\", \"Method A → B\", \"Beam Width\", \"bin\"]):\n",
    "    A = sum((g[\"Acc A\"] == 1) & (g[\"Acc B\"] == 1))\n",
    "    B = sum((g[\"Acc A\"] == 1) & (g[\"Acc B\"] == 0))\n",
    "    C = sum((g[\"Acc A\"] == 0) & (g[\"Acc B\"] == 1))\n",
    "    D = sum((g[\"Acc A\"] == 0) & (g[\"Acc B\"] == 0))\n",
    "\n",
    "    total = A + B + C + D\n",
    "    acc_A = (A + B) / total if total > 0 else 0\n",
    "    acc_B = (A + C) / total if total > 0 else 0\n",
    "    delta = acc_B - acc_A\n",
    "\n",
    "    if B + C >= 5:\n",
    "        try:\n",
    "            pval = mcnemar([[A, B], [C, D]], exact=True).pvalue\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] McNemar failed: {backbone}, {method_pair}, bin={bin_label}: {e}\")\n",
    "            pval = None\n",
    "    else:\n",
    "        pval = None\n",
    "\n",
    "    acc_str = (\n",
    "        f\"\\\\textbf{{{acc_B * 100:.1f}}} ({delta * 100:+.1f})\"\n",
    "        if pval is not None and pval < 0.05\n",
    "        else f\"{acc_B * 100:.1f} ({delta * 100:+.1f})\"\n",
    "    )\n",
    "\n",
    "    agg_records.append({\n",
    "        \"Backbone\": backbone,\n",
    "        \"Method A → B\": method_pair,\n",
    "        \"Beam Width\": beam_width,\n",
    "        \"Bin\": bin_label,\n",
    "        \"Acc A\": round(acc_A * 100, 1),\n",
    "        \"Acc B\": round(acc_B * 100, 1),\n",
    "        \"ΔAcc\": round(delta * 100, 1),\n",
    "        \"p-value\": pval,\n",
    "        \"acc_str\": acc_str\n",
    "    })\n",
    "\n",
    "# --- DataFrame化 & ピボット ---\n",
    "df_result = pd.DataFrame(agg_records)\n",
    "bin_order = labels + [\"Root\"]\n",
    "df_pivot = df_result.pivot(index=[\"Backbone\", \"Method A → B\", \"Beam Width\"], columns=\"Bin\", values=\"acc_str\").reset_index()\n",
    "for b in bin_order:\n",
    "    if b not in df_pivot.columns:\n",
    "        df_pivot[b] = \"\"\n",
    "df_pivot = df_pivot[[\"Backbone\", \"Method A → B\", \"Beam Width\"] + bin_order]\n",
    "\n",
    "# --- 表示 ---\n",
    "# print(\"\\n=== エッジ距離ビン別 Accuracy@B (+Δ) [p < 0.05 は太字] ===\")\n",
    "# print(df_pivot.to_string(index=False))\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "latex = df_pivot.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"lll\" + \"c\" * len(bin_order),\n",
    "    caption=r\"Accuracy@B per GT edge distance bin, comparing method A to B. Values in bold are statistically significant ($p < 0.05$) under McNemar's test.\",\n",
    "    label=\"tab:gt_edge_distance_accuracy\"\n",
    ")\n",
    "# print(\"\\n=== LaTeX ===\")\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5ef85-c97c-4195-8665-7f7fd5a77eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bin_significance(df_result, bin_order):\n",
    "    print(\"\\n=== 距離ビンごとの有意差 (p < 0.05, McNemar) ===\")\n",
    "    for (backbone, method_pair, beam_width), subdf in df_result.groupby([\"Backbone\", \"Method A → B\", \"Beam Width\"]):\n",
    "        print(f\"[Backbone={backbone} | {method_pair} | Beam={beam_width}]\")\n",
    "        line = \"  \"\n",
    "        for b in bin_order:\n",
    "            pval = subdf[subdf[\"Bin\"] == b][\"p-value\"]\n",
    "            if pval.empty:\n",
    "                mark = \"－\"\n",
    "            elif pval.iloc[0] is not None and pval.iloc[0] < 0.05:\n",
    "                mark = \"✔\"\n",
    "            else:\n",
    "                mark = \"✘\"\n",
    "            line += f\"{mark} {b:<10} \"\n",
    "        print(line)\n",
    "\n",
    "print_bin_significance(df_result, bin_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d468854-9571-4a64-aa57-df04256cbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd  # 念のため\n",
    "\n",
    "# --- ビン順序 ---\n",
    "bin_cols = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", \"(16, ∞)\"]\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "backbone_order = list(backbone_name_map.values())\n",
    "\n",
    "# --- \\textbf{...} の太字を外して $^\\star$ を付加する関数 ---\n",
    "def convert_textbf_to_star(cell):\n",
    "    if not isinstance(cell, str):\n",
    "        return cell\n",
    "    # パターン: \\textbf{XX.X} (+Y.Y)\n",
    "    m = re.match(r\"\\\\textbf{([\\d.]+)}\\s+\\(([-+.\\d]+)\\)\", cell)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} ({m.group(2)})$^\\\\star$\"\n",
    "    # fallback: 単に textbf を外す\n",
    "    cell = re.sub(r\"\\\\textbf{([^}]*)}\", r\"\\1\", cell)\n",
    "    cell = re.sub(r\"\\$\\\\\\star\\$|\\$\\\\\\^\\star\\$\", \"\", cell)\n",
    "    return cell.strip()\n",
    "\n",
    "# --- 抽出：DRGG → DRGGBBoxEmbTFEnc, Beam 20 (＝BEBS) ---\n",
    "df_bebs = df_pivot[\n",
    "    (df_pivot[\"Method A → B\"] == \"DRGG → DRGGBBoxEmbTFEnc\") &\n",
    "    (df_pivot[\"Beam Width\"] == 20)\n",
    "].copy()\n",
    "df_bebs[\"BackboneDisplay\"] = df_bebs[\"Backbone\"].map(backbone_name_map)\n",
    "\n",
    "# --- 有意差処理を含むフォーマット変換 ---\n",
    "for b in bin_cols:\n",
    "    df_bebs[b] = df_bebs[b].apply(convert_textbf_to_star)\n",
    "\n",
    "# --- 表示順に並べ替え ---\n",
    "df_bebs[\"BackboneDisplay\"] = pd.Categorical(df_bebs[\"BackboneDisplay\"], categories=backbone_order, ordered=True)\n",
    "df_bebs = df_bebs.sort_values(\"BackboneDisplay\")\n",
    "\n",
    "# --- LaTeX 出力 ---\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{l|rrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "lines.append(r\"Backbone & \" + \" & \".join(bin_cols) + r\" \\\\\")\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for _, row in df_bebs.iterrows():\n",
    "    vals = [row[b] for b in bin_cols]\n",
    "    line = f\"{row['BackboneDisplay']:<15} & \" + \" & \".join(vals) + r\" \\\\\"\n",
    "    lines.append(line)\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# --- 出力 ---\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8673a-7a62-448a-8b74-41b7972579f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "\n",
    "# 表示順・ラベル\n",
    "bin_cols = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", \"(16, ∞)\"]\n",
    "backbone_name_map = {\n",
    "    \"r50_4scale\": \"ResNet-50\",\n",
    "    \"vitdet_base_4scale\": \"ViT\",\n",
    "    \"swin_base_384_4scale\": \"Swin\",\n",
    "    \"dit_base\": \"DiT\",\n",
    "    \"internimage_base_4scale\": \"InternImage\",\n",
    "}\n",
    "backbone_order = list(backbone_name_map.values())\n",
    "decoder_map = {1: \"DRGG-BE\", 20: \"DRGG-BEBS\"}\n",
    "\n",
    "# textbf を $^\\star$ に変換\n",
    "def convert_textbf_to_star(cell):\n",
    "    if not isinstance(cell, str): return cell\n",
    "    m = re.match(r\"\\\\textbf{([\\d.]+)} \\(([-+.\\d]+)\\)\", cell)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} ({m.group(2)})$^\\\\star$\"\n",
    "    return re.sub(r\"\\\\textbf{([^}]*)}\", r\"\\1\", cell).strip()\n",
    "\n",
    "# 前処理：変換＋Backbone名整形\n",
    "df_pivot[\"BackboneDisplay\"] = df_pivot[\"Backbone\"].map(backbone_name_map)\n",
    "for b in bin_cols:\n",
    "    if b in df_pivot.columns:\n",
    "        df_pivot[b] = df_pivot[b].apply(convert_textbf_to_star)\n",
    "\n",
    "# レコード収集：Method A → B == DRGG → DRGGBBoxEmbTFEnc\n",
    "records = []\n",
    "for backbone in backbone_order:\n",
    "    for beam_width in [1, 20]:\n",
    "        decoder = decoder_map[beam_width]\n",
    "        row = df_pivot[\n",
    "            (df_pivot[\"BackboneDisplay\"] == backbone) &\n",
    "            (df_pivot[\"Method A → B\"] == \"DRGG → DRGGBBoxEmbTFEnc\") &\n",
    "            (df_pivot[\"Beam Width\"] == beam_width)\n",
    "        ]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        rec = {\"Backbone\": backbone, \"Decoder\": decoder}\n",
    "        for b in bin_cols:\n",
    "            rec[b] = row.iloc[0][b]\n",
    "        records.append(rec)\n",
    "\n",
    "# LaTeX 出力\n",
    "lines = []\n",
    "lines.append(r\"\\begin{tabular}{ll|rrrrrr}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "lines.append(r\"Backbone & Decoder & \" + \" & \".join(bin_cols) + r\" \\\\\")\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for backbone, group in groupby(records, key=lambda x: x[\"Backbone\"]):\n",
    "    group = list(group)\n",
    "    for i, row in enumerate(group):\n",
    "        vals = [row[b] for b in bin_cols]\n",
    "        if i == 0:\n",
    "            lines.append(rf\"\\multirow{{2}}{{*}}{{{backbone}}} & {row['Decoder']} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "        else:\n",
    "            lines.append(rf\"    & {row['Decoder']} & \" + \" & \".join(vals) + r\" \\\\\")\n",
    "    if backbone != backbone_order[-1]:\n",
    "        lines.append(r\"\\midrule\")\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "\n",
    "# 出力\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8c856-9768-4ad7-999d-60c7b2d9d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# bin 定義（+ \"Root\"）\n",
    "bins = [0, 1, 2, 4, 8, 16, np.inf]\n",
    "labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", r\"(16, $\\infty$)\", \"Root\"]\n",
    "\n",
    "bin_confusions_per_backbone = {b: defaultdict(Counter) for b in backbones}\n",
    "method = \"DRGGBBoxEmbTFEnc\"\n",
    "beam_width = 20\n",
    "\n",
    "def truncate_tree_at_node(root: TreeNode, stop_label: str) -> TreeNode | None:\n",
    "    \"\"\"\n",
    "    pred_tree を DFS 順に辿り、stop_label に達したらそれ以降を切り落とした部分木を返す。\n",
    "    \"\"\"\n",
    "    stopped = False  # 単なるフラグ\n",
    "\n",
    "    def dfs(node: TreeNode) -> TreeNode | None:\n",
    "        nonlocal stopped  # ← これだけでOK\n",
    "        if stopped:\n",
    "            return None\n",
    "        if node.label == stop_label:\n",
    "            stopped = True\n",
    "            return None\n",
    "\n",
    "        new_node = TreeNode(node.id, node.label, node.bbox, node.category)\n",
    "        for child in node.children:\n",
    "            if stopped:\n",
    "                break\n",
    "            child_copy = dfs(child)\n",
    "            if child_copy:\n",
    "                new_node.children.append(child_copy)\n",
    "        return new_node\n",
    "\n",
    "    return dfs(root)\n",
    "\n",
    "def get_rightmost_path(root):\n",
    "    path = []\n",
    "    node = root\n",
    "    while node and node.children:\n",
    "        path.append(node.id)\n",
    "        node = node.children[-1]\n",
    "    if node:\n",
    "        path.append(node.id)\n",
    "    return path\n",
    "\n",
    "correct_counts_per_backbone = defaultdict(int)\n",
    "mispred_counts_per_backbone = defaultdict(int)\n",
    "parent_status_counts = defaultdict(lambda: [0, 0, 0])\n",
    "\n",
    "for backbone in backbones:\n",
    "    key = (backbone, method, beam_width)\n",
    "    if key not in all_preds_dict:\n",
    "        print(f\"[WARN] Missing: {key}\")\n",
    "        continue\n",
    "\n",
    "    preds = all_preds_dict[key]\n",
    "\n",
    "    for entry in preds:\n",
    "        gt = entry[\"gt_tree\"]\n",
    "        pred = entry[\"pred_tree\"]\n",
    "\n",
    "        gt_edges = get_edges(gt, skip_root=False)\n",
    "        pred_edges = get_edges(pred, skip_root=False)\n",
    "\n",
    "        gt_nodes = build_node_dict(gt)\n",
    "        pred_nodes = build_node_dict(pred)\n",
    "\n",
    "        pred_parent_map = {cid: pid for pid, cid in pred_edges}\n",
    "\n",
    "        for pid, cid in gt_edges:\n",
    "            if pid not in gt_nodes or cid not in gt_nodes:\n",
    "                continue\n",
    "\n",
    "            # --- GT距離 ---\n",
    "            if gt_nodes[pid].category == -1:\n",
    "                bin_gt = \"Root\"\n",
    "            else:\n",
    "                x1, y1 = bbox_center(gt_nodes[pid].bbox)\n",
    "                x2, y2 = bbox_center(gt_nodes[cid].bbox)\n",
    "                dx, dy = abs(x2 - x1), abs(y2 - y1)\n",
    "\n",
    "                if dx >= dy:\n",
    "                    dist_gt = dx\n",
    "                    scale = max(\n",
    "                        gt_nodes[pid].bbox[2] - gt_nodes[pid].bbox[0],\n",
    "                        gt_nodes[cid].bbox[2] - gt_nodes[cid].bbox[0]\n",
    "                    )\n",
    "                else:\n",
    "                    dist_gt = dy\n",
    "                    scale = max(\n",
    "                        gt_nodes[pid].bbox[3] - gt_nodes[pid].bbox[1],\n",
    "                        gt_nodes[cid].bbox[3] - gt_nodes[cid].bbox[1]\n",
    "                    )\n",
    "\n",
    "                if scale == 0 or not np.isfinite(dist_gt / scale):\n",
    "                    bin_gt = \"Root\"\n",
    "                else:\n",
    "                    norm_dist_gt = dist_gt / scale\n",
    "                    bin_gt = pd.cut([norm_dist_gt], bins=bins, labels=labels[:-1])[0]\n",
    "\n",
    "            if cid not in pred_parent_map:\n",
    "                continue\n",
    "             # --- 正解ならスキップ ---\n",
    "            if pred_parent_map[cid] == pid:\n",
    "                correct_counts_per_backbone[backbone] += 1\n",
    "                continue\n",
    "\n",
    "            pred_pid = pred_parent_map[cid]\n",
    "\n",
    "            # --- Pred距離 ---\n",
    "            if pred_pid not in pred_nodes or pred_nodes[pred_pid].category == -1:\n",
    "                bin_pred = \"Root\"\n",
    "            else:\n",
    "                px1, py1 = bbox_center(pred_nodes[pred_pid].bbox)\n",
    "                px2, py2 = bbox_center(pred_nodes[cid].bbox)\n",
    "                dxp, dyp = abs(px2 - px1), abs(py2 - py1)\n",
    "\n",
    "                if dxp >= dyp:\n",
    "                    dist_pred = dxp\n",
    "                    scale_p = max(\n",
    "                        pred_nodes[pred_pid].bbox[2] - pred_nodes[pred_pid].bbox[0],\n",
    "                        pred_nodes[cid].bbox[2] - pred_nodes[cid].bbox[0]\n",
    "                    )\n",
    "                else:\n",
    "                    dist_pred = dyp\n",
    "                    scale_p = max(\n",
    "                        pred_nodes[pred_pid].bbox[3] - pred_nodes[pred_pid].bbox[1],\n",
    "                        pred_nodes[cid].bbox[3] - pred_nodes[cid].bbox[1]\n",
    "                    )\n",
    "\n",
    "                if scale_p == 0 or not np.isfinite(dist_pred / scale_p):\n",
    "                    bin_pred = \"Root\"\n",
    "                else:\n",
    "                    norm_dist_pred = dist_pred / scale_p\n",
    "                    bin_pred = pd.cut([norm_dist_pred], bins=bins, labels=labels[:-1])[0]\n",
    "\n",
    "            # --- 集計 ---\n",
    "            bin_confusions_per_backbone[backbone][bin_gt][bin_pred] += 1\n",
    "            mispred_counts_per_backbone[backbone] += 1\n",
    "\n",
    "            # 部分木構築\n",
    "            partial_tree = truncate_tree_at_node(pred, pred_nodes[cid].label)\n",
    "            if not partial_tree:\n",
    "                parent_status_counts[backbone][2] += 1\n",
    "                continue\n",
    "        \n",
    "            rightmost_path = set(get_rightmost_path(partial_tree))\n",
    "            all_labels_in_tree = set(n.label for n in dfs_all_nodes(partial_tree))\n",
    "                \n",
    "            if gt_nodes[pid].label in rightmost_path:\n",
    "                parent_status_counts[backbone][0] += 1  # right frontier にいた\n",
    "            elif gt_nodes[pid].label in all_labels_in_tree:\n",
    "                parent_status_counts[backbone][1] += 1  # 構築済みにいたが frontier にいなかった\n",
    "            else:\n",
    "                parent_status_counts[backbone][2] += 1  # まだ構築されていない（読み順の矛盾）\n",
    "\n",
    "print(\"\\n=== mispredicted距離割合（backboneごと）===\")\n",
    "mispred_rates = []\n",
    "for backbone in backbones:\n",
    "    correct = correct_counts_per_backbone[backbone]\n",
    "    mispred = mispred_counts_per_backbone[backbone]\n",
    "    total = correct + mispred\n",
    "    if total > 0:\n",
    "        rate = 100 * mispred / total\n",
    "        print(f\"[{backbone}] {rate:.2f}%  ({mispred} / {total})\")\n",
    "        mispred_rates.append(rate)\n",
    "    else:\n",
    "        print(f\"[{backbone}] データなし\")\n",
    "\n",
    "if mispred_rates:\n",
    "    print(f\"\\n=== mispredicted方向割合（backbone平均）: {sum(mispred_rates)/len(mispred_rates):.2f}% ===\")\n",
    "else:\n",
    "    print(\"\\n=== mispredicted方向割合を計算できません（全backboneでデータなし） ===\")\n",
    "\n",
    "print(\"\\n=== 正解親の構築時点の分類（backboneごと） ===\")\n",
    "avg_ratios = [0, 0, 0]  # [in_frontier, in_tree, not_built]\n",
    "valid_backbones = 0\n",
    "for backbone, (in_frontier, in_tree, not_built) in parent_status_counts.items():\n",
    "    total = in_frontier + in_tree + not_built\n",
    "    if total == 0:\n",
    "        continue\n",
    "    r1 = in_frontier / total * 100\n",
    "    r2 = in_tree / total * 100\n",
    "    r3 = not_built / total * 100\n",
    "    print(f\"[{backbone}]\")\n",
    "    print(f\"  1. rightmost path に存在       : {in_frontier} ({r1:.2f}%)\")\n",
    "    print(f\"  2. rightmost path 以外の木に存在: {in_tree} ({r2:.2f}%)\")\n",
    "    print(f\"  3. 正解の親が子より後ろの読み順  : {not_built} ({r3:.2f}%)\")\n",
    "    avg_ratios[0] += r1\n",
    "    avg_ratios[1] += r2\n",
    "    avg_ratios[2] += r3\n",
    "    valid_backbones += 1\n",
    "\n",
    "if valid_backbones > 0:\n",
    "    print(\"\\n=== 分類割合（backbone平均） ===\")\n",
    "    print(f\"  1. rightmost path に存在       : {avg_ratios[0]/valid_backbones:.2f}%\")\n",
    "    print(f\"  2. rightmost path 以外の木に存在: {avg_ratios[1]/valid_backbones:.2f}%\")\n",
    "    print(f\"  3. 正解の親が子より後ろの読み順  : {avg_ratios[2]/valid_backbones:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n=== データなし：backbone 平均は計算不可 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3fc9d-72fd-4720-b5e8-66bf1e1dd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 必ず bin ラベル順に並べる\n",
    "labels = [\"(0, 1]\", \"(1, 2]\", \"(2, 4]\", \"(4, 8]\", \"(8, 16]\", r\"(16, $\\infty$)\", \"Root\"]\n",
    "\n",
    "normalized_dfs = []\n",
    "\n",
    "for backbone, counter in bin_confusions_per_backbone.items():\n",
    "    # 元データを DataFrame に変換\n",
    "    df = pd.DataFrame.from_dict(counter, orient=\"index\", columns=labels).reindex(index=labels, columns=labels)\n",
    "    df = df.fillna(0).astype(float)\n",
    "\n",
    "    # 行ごとに正規化（各 GT bin に対する割合）\n",
    "    row_sums = df.sum(axis=1)\n",
    "    df_norm = df.div(row_sums, axis=0).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    normalized_dfs.append(df_norm)\n",
    "\n",
    "# NaN を無視して平均（セル単位）\n",
    "stack = np.stack([df.to_numpy() for df in normalized_dfs])\n",
    "mean_array = np.nanmean(stack, axis=0)\n",
    "mean_bin_confusion = pd.DataFrame(mean_array, index=labels, columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d33b8c-36e7-4aac-8e6e-9ed638e5c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "ax = sns.heatmap(\n",
    "    mean_bin_confusion,\n",
    "    # annot=True,\n",
    "    # fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "plt.xlabel(\"Distance of Mispredicted BBox\", fontsize=18)\n",
    "plt.ylabel(\"Distance of GT BBox\", fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=18)\n",
    "plt.yticks(rotation=0, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/parent_child_error_distance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"./figures/parent_child_error_distance.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452bf2a-e08a-46aa-b00f-b4f6b75b2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2category = {\n",
    "    0: \"Author_Info\",\n",
    "    1: \"Title\",\n",
    "    2: \"Figure\",\n",
    "    3: \"Text\",\n",
    "    4: \"List\",\n",
    "    5: \"Section\",\n",
    "    6: \"Caption\",\n",
    "    7: \"Table\",\n",
    "    8: \"Unknown\",\n",
    "    9: \"Root\",\n",
    "   -1: \"Root\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb007602-70c4-432e-a19b-5d9ecd78934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# ----- ID辞書作成 -----\n",
    "def build_node_dict(node):\n",
    "    nodes = {}\n",
    "    def recurse(n):\n",
    "        nodes[n.label] = n\n",
    "        for c in n.children:\n",
    "            recurse(c)\n",
    "    recurse(node)\n",
    "    return nodes\n",
    "\n",
    "# ----- パラメータ -----\n",
    "backbones = [\"r50_4scale\", \"vitdet_base_4scale\", \"swin_base_384_4scale\", \"internimage_base_4scale\", \"dit_base\"]\n",
    "methods = [(\"DRGG\", \"DRGGBBoxEmbTFEnc\")]\n",
    "beam_widths = [1, 20]\n",
    "\n",
    "# ----- 集計結果 -----\n",
    "category_stats = defaultdict(lambda: {\"total\": 0, \"correct_A\": 0, \"correct_B\": 0})\n",
    "\n",
    "for backbone in backbones:\n",
    "    for method_A, method_B in methods:\n",
    "        for beam_width in beam_widths:\n",
    "            key_A = (backbone, method_A, beam_width)\n",
    "            key_B = (backbone, method_B, beam_width)\n",
    "\n",
    "            if key_A not in all_preds_dict or key_B not in all_preds_dict:\n",
    "                print(f\"[WARN] Missing: {key_A} or {key_B}\")\n",
    "                continue\n",
    "\n",
    "            preds_A = all_preds_dict[key_A]\n",
    "            preds_B = all_preds_dict[key_B]\n",
    "            map_A = {p[\"file_name\"]: p for p in preds_A}\n",
    "            map_B = {p[\"file_name\"]: p for p in preds_B}\n",
    "            common_files = set(map_A) & set(map_B)\n",
    "\n",
    "            for fname in sorted(common_files):\n",
    "                gt = map_A[fname][\"gt_tree\"]\n",
    "                pred_A = map_A[fname][\"pred_tree\"]\n",
    "                pred_B = map_B[fname][\"pred_tree\"]\n",
    "\n",
    "                gt_edges = get_edges(gt, skip_root=False)\n",
    "                pred_edges_A = set(get_edges(pred_A, skip_root=False))\n",
    "                pred_edges_B = set(get_edges(pred_B, skip_root=False))\n",
    "\n",
    "                node_dict = build_node_dict(gt)\n",
    "\n",
    "                for pid, cid in gt_edges:\n",
    "                    if pid not in node_dict or cid not in node_dict:\n",
    "                        continue\n",
    "                    parent, child = node_dict[pid], node_dict[cid]\n",
    "                    key = (backbone, method_A, method_B, beam_width, f\"{id2category[parent.category]} → {id2category[child.category]}\")\n",
    "                    category_stats[key][\"total\"] += 1\n",
    "                    category_stats[key][\"correct_A\"] += int((pid, cid) in pred_edges_A)\n",
    "                    category_stats[key][\"correct_B\"] += int((pid, cid) in pred_edges_B)\n",
    "\n",
    "# ----- 整形と出力 -----\n",
    "records = []\n",
    "for (backbone, method_A, method_B, beam_width, pair), stat in category_stats.items():\n",
    "    total = stat[\"total\"]\n",
    "    acc_A = stat[\"correct_A\"] / total * 100 if total else 0\n",
    "    acc_B = stat[\"correct_B\"] / total * 100 if total else 0\n",
    "    diff = acc_B - acc_A\n",
    "    records.append({\n",
    "        \"Backbone\": backbone,\n",
    "        \"Method A → B\": f\"{method_A} → {method_B}\",\n",
    "        \"Beam Width\": beam_width,\n",
    "        \"Parent → Child\": pair,\n",
    "        \"Count\": total,\n",
    "        \"Acc A (%)\": round(acc_A, 2),\n",
    "        \"Acc B (%)\": round(acc_B, 2),\n",
    "        \"Diff (%)\": round(diff, 2)\n",
    "    })\n",
    "\n",
    "df_cat = pd.DataFrame(records)\n",
    "df_cat = df_cat.sort_values(by=[\"Backbone\", \"Beam Width\", \"Diff (%)\"], ascending=[True, True, False])\n",
    "\n",
    "# # ----- 表示 -----\n",
    "# pd.set_option(\"display.max_rows\", 100)\n",
    "# print(df_cat.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3ba99-5d64-4099-a2c6-9843560e6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5  # 上位N件を出力\n",
    "latex_tables = []\n",
    "\n",
    "group_cols = [\"Backbone\", \"Method A → B\", \"Beam Width\"]\n",
    "\n",
    "# グループごとに上位N件抽出\n",
    "for key, group in df_cat.groupby(group_cols):\n",
    "    topn = group.sort_values(by=\"Diff (%)\", ascending=False).head(N)\n",
    "    caption = f\"Top-{N} improved parent-child relations for {key[0]}, {key[1]}, Beam Width={key[2]}\"\n",
    "    label = f\"tab:top{N}_{key[0]}_{key[1].replace(' ', '')}_bw{key[2]}\".lower().replace(\"→\", \"to\").replace(\"_\", \"\")\n",
    "    \n",
    "    latex = topn.to_latex(\n",
    "        index=False,\n",
    "        columns=[\"Parent → Child\", \"Count\", \"Acc A (%)\", \"Acc B (%)\", \"Diff (%)\"],\n",
    "        float_format=\"%.2f\",\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        escape=False,\n",
    "        column_format=\"lrrrr\"\n",
    "    )\n",
    "    latex_tables.append(latex)\n",
    "\n",
    "# 出力\n",
    "for t in latex_tables:\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c739c09-5cd1-4e92-ba56-8365b728feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "\n",
    "method = \"DRGGBBoxEmbTFEnc\"\n",
    "beam_width = 20\n",
    "parent_confusions_per_backbone = {}\n",
    "\n",
    "def truncate_tree_at_node(root: TreeNode, stop_label: str) -> TreeNode | None:\n",
    "    \"\"\"\n",
    "    pred_tree を DFS 順に辿り、stop_label に達したらそれ以降を切り落とした部分木を返す。\n",
    "    \"\"\"\n",
    "    stopped = False  # 単なるフラグ\n",
    "\n",
    "    def dfs(node: TreeNode) -> TreeNode | None:\n",
    "        nonlocal stopped  # ← これだけでOK\n",
    "        if stopped:\n",
    "            return None\n",
    "        if node.label == stop_label:\n",
    "            stopped = True\n",
    "            return None\n",
    "\n",
    "        new_node = TreeNode(node.id, node.label, node.bbox, node.category)\n",
    "        for child in node.children:\n",
    "            if stopped:\n",
    "                break\n",
    "            child_copy = dfs(child)\n",
    "            if child_copy:\n",
    "                new_node.children.append(child_copy)\n",
    "        return new_node\n",
    "\n",
    "    return dfs(root)\n",
    "\n",
    "def get_rightmost_path(root):\n",
    "    path = []\n",
    "    node = root\n",
    "    while node and node.children:\n",
    "        path.append(node.id)\n",
    "        node = node.children[-1]\n",
    "    if node:\n",
    "        path.append(node.id)\n",
    "    return path\n",
    "\n",
    "correct_counts_per_backbone = defaultdict(int)\n",
    "mispred_counts_per_backbone = defaultdict(int)\n",
    "parent_status_counts = defaultdict(lambda: [0, 0, 0])\n",
    "\n",
    "for backbone in backbones:\n",
    "    key = (backbone, method, beam_width)\n",
    "    if key not in all_preds_dict:\n",
    "        print(f\"[WARN] Missing: {key}\")\n",
    "        continue\n",
    "\n",
    "    preds = all_preds_dict[key]\n",
    "    confusion = defaultdict(Counter)\n",
    "\n",
    "    for entry in preds:\n",
    "        gt = entry[\"gt_tree\"]\n",
    "        pred = entry[\"pred_tree\"]\n",
    "\n",
    "        gt_edges = get_edges(gt, skip_root=False)\n",
    "        pred_edges = get_edges(pred, skip_root=False)\n",
    "\n",
    "        gt_nodes = build_node_dict(gt)\n",
    "        pred_nodes = build_node_dict(pred)\n",
    "\n",
    "        # --- GT: 子→親マップ（labelベース） ---\n",
    "        gt_parents = {cid: pid for pid, cid in gt_edges}\n",
    "\n",
    "        # --- Pred: 子→親マップ（labelベース） ---\n",
    "        pred_parents = {cid: pid for pid, cid in pred_edges}\n",
    "\n",
    "        for cid_label, pid_gt_label in gt_parents.items():\n",
    "            if cid_label not in pred_parents:\n",
    "                continue  # 子ノードが予測に存在しない\n",
    "\n",
    "            pid_pred_label = pred_parents[cid_label]\n",
    "            if pid_gt_label == pid_pred_label:\n",
    "                correct_counts_per_backbone[backbone] += 1\n",
    "                continue  # 正解なのでスキップ\n",
    "\n",
    "            # ノード整合性チェック\n",
    "            # if pid_gt_label not in gt_nodes or pid_pred_label not in pred_nodes:\n",
    "            #     continue\n",
    "\n",
    "            cat_gt = id2category[gt_nodes[pid_gt_label].category]\n",
    "            cat_pred = id2category[pred_nodes[pid_pred_label].category]\n",
    "\n",
    "            confusion[cat_gt][cat_pred] += 1\n",
    "            mispred_counts_per_backbone[backbone] += 1\n",
    "        \n",
    "            # 部分木構築\n",
    "            partial_tree = truncate_tree_at_node(pred, cid_label)\n",
    "            if not partial_tree:\n",
    "                parent_status_counts[backbone][2] += 1\n",
    "                continue\n",
    "        \n",
    "            rightmost_path = set(get_rightmost_path(partial_tree))\n",
    "            all_labels_in_tree = set(n.label for n in dfs_all_nodes(partial_tree))\n",
    "\n",
    "            # # 正解が Section, 予測が Root の場合だけを集計\n",
    "            # if not(cat_gt == \"Section\" and cat_pred == \"Root\"):\n",
    "            #     continue\n",
    "                \n",
    "            if pid_gt_label in rightmost_path:\n",
    "                parent_status_counts[backbone][0] += 1  # right frontier にいた\n",
    "            elif pid_gt_label in all_labels_in_tree:\n",
    "                parent_status_counts[backbone][1] += 1  # 構築済みにいたが frontier にいなかった\n",
    "            else:\n",
    "                parent_status_counts[backbone][2] += 1  # まだ構築されていない（読み順の矛盾）\n",
    "\n",
    "    parent_confusions_per_backbone[backbone] = confusion\n",
    "\n",
    "# 表示順\n",
    "category_order = [\n",
    "    \"Root\", \"Title\", \"Author Info\", \"Section\",\n",
    "    \"Text\", \"List\", \"Figure\", \"Table\", \"Caption\"\n",
    "]\n",
    "\n",
    "# 全カテゴリ収集\n",
    "all_cats = sorted(set(\n",
    "    k for conf in parent_confusions_per_backbone.values() for k in conf\n",
    ").union(\n",
    "    k2 for conf in parent_confusions_per_backbone.values() for v in conf.values() for k2 in v\n",
    "))\n",
    "\n",
    "# 平均処理\n",
    "normalized_dfs = []\n",
    "for backbone in backbones:\n",
    "    conf = parent_confusions_per_backbone.get(backbone, {})\n",
    "    df = pd.DataFrame.from_dict(conf, orient=\"index\", columns=all_cats).fillna(0).astype(int)\n",
    "    df = df.reindex(index=all_cats, columns=all_cats).fillna(0)\n",
    "    df_norm = df.div(df.sum(axis=1), axis=0).fillna(0)\n",
    "    normalized_dfs.append(df_norm)\n",
    "\n",
    "mean_confusion = sum(normalized_dfs) / len(normalized_dfs)\n",
    "\n",
    "# 0 行列削除\n",
    "nonzero_rows = mean_confusion.sum(axis=1) > 0\n",
    "nonzero_cols = mean_confusion.sum(axis=0) > 0\n",
    "mean_confusion = mean_confusion.loc[nonzero_rows, nonzero_cols]\n",
    "\n",
    "# 表示順に並び替え（存在するカテゴリのみ）\n",
    "present_rows = [cat for cat in category_order if cat in mean_confusion.index]\n",
    "present_cols = [cat for cat in category_order if cat in mean_confusion.columns]\n",
    "mean_confusion = mean_confusion.reindex(index=present_rows, columns=present_cols)\n",
    "\n",
    "print(\"\\n=== mispredictedカテゴリー割合（backboneごと）===\")\n",
    "mispred_rates = []\n",
    "for backbone in backbones:\n",
    "    correct = correct_counts_per_backbone[backbone]\n",
    "    mispred = mispred_counts_per_backbone[backbone]\n",
    "    total = correct + mispred\n",
    "    if total > 0:\n",
    "        rate = 100 * mispred / total\n",
    "        print(f\"[{backbone}] {rate:.2f}%  ({mispred} / {total})\")\n",
    "        mispred_rates.append(rate)\n",
    "    else:\n",
    "        print(f\"[{backbone}] データなし\")\n",
    "\n",
    "if mispred_rates:\n",
    "    print(f\"\\n=== mispredicted方向割合（backbone平均）: {sum(mispred_rates)/len(mispred_rates):.2f}% ===\")\n",
    "else:\n",
    "    print(\"\\n=== mispredicted方向割合を計算できません（全backboneでデータなし） ===\")\n",
    "\n",
    "print(\"\\n=== 正解親の構築時点の分類（backboneごと） ===\")\n",
    "avg_ratios = [0, 0, 0]  # [in_frontier, in_tree, not_built]\n",
    "valid_backbones = 0\n",
    "for backbone, (in_frontier, in_tree, not_built) in parent_status_counts.items():\n",
    "    total = in_frontier + in_tree + not_built\n",
    "    if total == 0:\n",
    "        continue\n",
    "    r1 = in_frontier / total * 100\n",
    "    r2 = in_tree / total * 100\n",
    "    r3 = not_built / total * 100\n",
    "    print(f\"[{backbone}]\")\n",
    "    print(f\"  1. rightmost path に存在       : {in_frontier} ({r1:.2f}%)\")\n",
    "    print(f\"  2. rightmost path 以外の木に存在: {in_tree} ({r2:.2f}%)\")\n",
    "    print(f\"  3. 正解の親が子より後ろの読み順  : {not_built} ({r3:.2f}%)\")\n",
    "    avg_ratios[0] += r1\n",
    "    avg_ratios[1] += r2\n",
    "    avg_ratios[2] += r3\n",
    "    valid_backbones += 1\n",
    "\n",
    "if valid_backbones > 0:\n",
    "    print(\"\\n=== 分類割合（backbone平均） ===\")\n",
    "    print(f\"  1. rightmost path に存在       : {avg_ratios[0]/valid_backbones:.2f}%\")\n",
    "    print(f\"  2. rightmost path 以外の木に存在: {avg_ratios[1]/valid_backbones:.2f}%\")\n",
    "    print(f\"  3. 正解の親が子より後ろの読み順  : {avg_ratios[2]/valid_backbones:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n=== データなし：backbone 平均は計算不可 ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e6ec8-f5cb-4fda-80ea-fbfae7b60a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 2.5))\n",
    "ax = sns.heatmap(\n",
    "    mean_confusion,\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=mean_confusion.columns,\n",
    "    yticklabels=mean_confusion.index,\n",
    "    # annot=True,\n",
    "    # fmt=\".2f\"\n",
    ")\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "plt.xlabel(\"Category of Mispredicted BBox\", fontsize=18)\n",
    "plt.ylabel(\"Category\\nof GT BBox\", fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=18)\n",
    "plt.yticks(rotation=0, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/parent_child_error_category.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"./figures/parent_child_error_category.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
